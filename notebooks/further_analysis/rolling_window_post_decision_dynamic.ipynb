{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Window Analysis: PRE to POST Decision Period (Dynamic Feature Extraction)\n",
    "\n",
    "This notebook analyzes how model performance changes as we incrementally expand the analysis window from the PRE-decision period into the POST-decision period.\n",
    "\n",
    "**Key Difference from Static Version:**\n",
    "- This notebook **dynamically extracts POST features** for each rolling window\n",
    "- Each window (0-0.2s, 0-0.4s, etc.) gets its own POST physiology features\n",
    "- Slower but provides true rolling window analysis\n",
    "\n",
    "**Analysis Strategy:**\n",
    "1. Load PRE features (pre-extracted)\n",
    "2. For each window, dynamically extract POST features from preprocessing files\n",
    "3. Train fusion model with PRE + window-specific POST features\n",
    "4. Visualize how performance evolves with increasing POST window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ROLLING WINDOW ANALYSIS (DYNAMIC): PRE → POST DECISION PERIOD\n",
      "================================================================================\n",
      "\n",
      "Analysis started: 2026-01-09 14:11:54\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project utilities\n",
    "from src.utils.io import save_results\n",
    "from src.utils.config import get_model_params\n",
    "from src.models.fusion import weighted_late_fusion\n",
    "from src.visualization.plots import set_style\n",
    "\n",
    "np.random.seed(42)\n",
    "set_style('whitegrid')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ROLLING WINDOW ANALYSIS (DYNAMIC): PRE → POST DECISION PERIOD\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Rolling Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 11 rolling windows:\n",
      "\n",
      "Window Details:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. PRE Only                  | Baseline: PRE-decision only (-2.0 to 0.0s)\n",
      " 2. PRE+POST[0→0.2s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 0.2s)\n",
      " 3. PRE+POST[0→0.4s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 0.4s)\n",
      " 4. PRE+POST[0→0.6s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 0.6s)\n",
      " 5. PRE+POST[0→0.8s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 0.8s)\n",
      " 6. PRE+POST[0→1.0s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 1.0s)\n",
      " 7. PRE+POST[0→1.2s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 1.2s)\n",
      " 8. PRE+POST[0→1.4s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 1.4s)\n",
      " 9. PRE+POST[0→1.6s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 1.6s)\n",
      "10. PRE+POST[0→1.8s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 1.8s)\n",
      "11. PRE+POST[0→2.0s]          | PRE (-2.0 to 0.0s) + POST (0.0 to 2.0s)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define rolling window endpoints\n",
    "PRE_START = -2.0\n",
    "PRE_END = 0.0\n",
    "POST_STEP = 0.2  # Increment size for POST expansion\n",
    "POST_MAX = 2.0   # Maximum POST time\n",
    "\n",
    "# Generate windows\n",
    "windows = []\n",
    "\n",
    "# Window 1: PRE only\n",
    "windows.append({\n",
    "    'name': 'PRE Only',\n",
    "    'pre_window': (PRE_START, PRE_END),\n",
    "    'post_window': None,\n",
    "    'description': 'Baseline: PRE-decision only (-2.0 to 0.0s)'\n",
    "})\n",
    "\n",
    "# Windows 2+: PRE + incremental POST\n",
    "post_endpoints = np.arange(POST_STEP, POST_MAX + POST_STEP, POST_STEP)\n",
    "for post_end in post_endpoints:\n",
    "    windows.append({\n",
    "        'name': f'PRE+POST[0→{post_end:.1f}s]',\n",
    "        'pre_window': (PRE_START, PRE_END),\n",
    "        'post_window': (0.0, post_end),\n",
    "        'description': f'PRE (-2.0 to 0.0s) + POST (0.0 to {post_end:.1f}s)'\n",
    "    })\n",
    "\n",
    "print(f\"Created {len(windows)} rolling windows:\")\n",
    "print(\"\\nWindow Details:\")\n",
    "print(\"-\" * 80)\n",
    "for i, w in enumerate(windows):\n",
    "    print(f\"{i+1:2d}. {w['name']:25s} | {w['description']}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load PRE Features\n",
    "\n",
    "PRE features are pre-extracted and loaded once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PRE-decision features...\n",
      "  PRE trials: 12511\n",
      "  PRE subjects: 97\n",
      "  PRE features: 13 physio + 7 behavior + 20 gaze\n",
      "\n",
      "✓ PRE features loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading PRE-decision features...\")\n",
    "with open('../../data/results/features_PRE/extracted_features_PRE.pkl', 'rb') as f:\n",
    "    pre_data = pickle.load(f)\n",
    "\n",
    "pre_df = pre_data['merged_df']\n",
    "pre_physio_cols = pre_data['physio_cols']\n",
    "pre_behavior_cols = pre_data['behavior_cols']\n",
    "pre_gaze_cols = pre_data['gaze_cols']\n",
    "\n",
    "print(f\"  PRE trials: {len(pre_df)}\")\n",
    "print(f\"  PRE subjects: {pre_df['subject_id'].nunique()}\")\n",
    "print(f\"  PRE features: {len(pre_physio_cols)} physio + {len(pre_behavior_cols)} behavior + {len(pre_gaze_cols)} gaze\")\n",
    "print(f\"\\n✓ PRE features loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Dynamic POST Feature Extraction\n",
    "\n",
    "Extract POST physiology features for a specific time window from preprocessing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ POST feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_post_physio_for_window(time_window, baseline_method='t3_stable_pre_decision'):\n",
    "    \"\"\"\n",
    "    Extract POST physiology features for a specific time window.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_window : tuple\n",
    "        (start, end) in seconds relative to submit (e.g., (0.0, 0.2))\n",
    "    baseline_method : str\n",
    "        Baseline correction method name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with trial_id, subject_id, and POST physiology features\n",
    "    \"\"\"\n",
    "    preprocessing_dir = Path('../../data/results/preprocessing_outputs/preprocessing')\n",
    "    preprocessing_files = sorted(preprocessing_dir.glob('preprocessing_*.json'))\n",
    "    raw_dir = Path('../../data/raw/json')\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    for preprocessed_file in preprocessing_files:\n",
    "        with open(preprocessed_file, 'r') as f:\n",
    "            preprocessed = json.load(f)\n",
    "        \n",
    "        subject_id = preprocessed['subject_id']\n",
    "        \n",
    "        # Find matching raw JSON\n",
    "        matches = list(raw_dir.glob(f\"*{subject_id.split('_')[-1]}.json\"))\n",
    "        pattern = subject_id.replace(\"_\", \".*\")\n",
    "        match = next((f for f in matches if re.search(pattern, f.name)), None)\n",
    "        if not match:\n",
    "            continue\n",
    "        \n",
    "        with open(match, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "        \n",
    "        for trial_id, trial_data in preprocessed['trial_data'].items():\n",
    "            method_data = trial_data['methods'][baseline_method]\n",
    "            \n",
    "            if method_data['success'] != True:\n",
    "                continue\n",
    "            \n",
    "            raw_trial = raw_data['trials'][int(trial_id)-1]\n",
    "            if not raw_trial['gamble details']['submitted']:\n",
    "                continue\n",
    "            \n",
    "            # Extract pupil data\n",
    "            time_aligned = np.array(trial_data['time_relative_to_submit'])\n",
    "            pupil_avg = np.array(method_data['pupil_avg_baselined'])\n",
    "            pupil_L = np.array(method_data['pupil_L_baselined'])\n",
    "            pupil_R = np.array(method_data['pupil_R_baselined'])\n",
    "            \n",
    "            # Clean NaN values\n",
    "            valid_mask = ~np.isnan(pupil_avg)\n",
    "            pupil_avg_clean = pupil_avg[valid_mask]\n",
    "            pupil_L_clean = pupil_L[valid_mask]\n",
    "            pupil_R_clean = pupil_R[valid_mask]\n",
    "            time_clean = time_aligned[valid_mask]\n",
    "            \n",
    "            if len(pupil_avg_clean) < 20:\n",
    "                continue\n",
    "            \n",
    "            # Filter to specific POST window\n",
    "            time_mask = (time_clean > time_window[0]) & (time_clean <= time_window[1])\n",
    "            pupil = pupil_avg_clean[time_mask]\n",
    "            pupil_L_filtered = pupil_L_clean[time_mask]\n",
    "            pupil_R_filtered = pupil_R_clean[time_mask]\n",
    "            time_filtered = time_clean[time_mask]\n",
    "            \n",
    "            if len(pupil) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Calculate derivatives\n",
    "            pupil_velocity = np.diff(pupil) if len(pupil) > 1 else np.array([0])\n",
    "            pupil_acceleration = np.diff(pupil_velocity) if len(pupil_velocity) > 1 else np.array([0])\n",
    "            dilation_mask = pupil_velocity > 0 if len(pupil_velocity) > 0 else np.array([False])\n",
    "            \n",
    "            # Extract features\n",
    "            features = {\n",
    "                'trial_id': f\"{trial_id}_{subject_id}\",\n",
    "                'subject_id': subject_id,\n",
    "                'pupil_mean_post_window': np.mean(pupil),\n",
    "                'pupil_std_post_window': np.std(pupil),\n",
    "                'pupil_slope_post_window': np.polyfit(time_filtered, pupil, 1)[0] if len(time_filtered) > 1 else 0,\n",
    "                'time_to_peak_post_window': time_filtered[np.argmax(pupil)] - time_filtered[0] if len(time_filtered) > 0 else 0,\n",
    "                'pupil_cv_post_window': np.std(pupil) / np.abs(np.mean(pupil)) if (len(pupil) > 0 and np.mean(pupil) != 0) else 0,\n",
    "                'pupil_velocity_mean_post_window': np.mean(np.abs(pupil_velocity)) if len(pupil_velocity) > 0 else 0,\n",
    "                'pupil_max_dilation_rate_post_window': np.max(pupil_velocity) if len(pupil_velocity) > 0 else 0,\n",
    "                'pupil_max_constriction_rate_post_window': np.abs(np.min(pupil_velocity)) if len(pupil_velocity) > 0 else 0,\n",
    "                'pupil_acceleration_std_post_window': np.std(pupil_acceleration) if len(pupil_acceleration) > 1 else 0,\n",
    "                'pct_time_dilating_post_window': np.mean(dilation_mask) if len(dilation_mask) > 0 else 0,\n",
    "                'num_dilation_peaks_post_window': np.sum(np.diff(np.sign(pupil_velocity)) > 0) if len(pupil_velocity) > 1 else 0,\n",
    "                'eye_asymmetry_post_window': np.nanmean(np.abs(pupil_L_filtered - pupil_R_filtered)) if len(pupil_L_filtered) > 0 else 0,\n",
    "                'eye_asymmetry_std_post_window': np.nanstd(pupil_L_filtered - pupil_R_filtered) if len(pupil_L_filtered) > 1 else 0,\n",
    "            }\n",
    "            \n",
    "            all_features.append(features)\n",
    "    \n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "print(\"✓ POST feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Rolling Window Analysis\n",
    "\n",
    "For each window, extract POST features dynamically and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING ROLLING WINDOW ANALYSIS (DYNAMIC)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Window 1/11: PRE Only\n",
      "  Baseline: PRE-decision only (-2.0 to 0.0s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Using PRE features only: 13 physio\n",
      "  Feature shapes: Physio=(12511, 13), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6931 ± 0.0133\n",
      "    F1-Score: 0.6794 ± 0.0157\n",
      "    Weights: Physio=0.031, Behavior=0.967, Gaze=0.002\n",
      "\n",
      "Window 2/11: PRE+POST[0→0.2s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 0.2s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(0.2))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6940 ± 0.0133\n",
      "    F1-Score: 0.6808 ± 0.0156\n",
      "    Weights: Physio=0.029, Behavior=0.968, Gaze=0.002\n",
      "\n",
      "Window 3/11: PRE+POST[0→0.4s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 0.4s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(0.4))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6931 ± 0.0134\n",
      "    F1-Score: 0.6795 ± 0.0158\n",
      "    Weights: Physio=0.031, Behavior=0.967, Gaze=0.002\n",
      "\n",
      "Window 4/11: PRE+POST[0→0.6s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 0.6s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(0.6000000000000001))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6947 ± 0.0135\n",
      "    F1-Score: 0.6806 ± 0.0159\n",
      "    Weights: Physio=0.035, Behavior=0.963, Gaze=0.002\n",
      "\n",
      "Window 5/11: PRE+POST[0→0.8s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 0.8s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(0.8))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6942 ± 0.0135\n",
      "    F1-Score: 0.6801 ± 0.0158\n",
      "    Weights: Physio=0.040, Behavior=0.957, Gaze=0.002\n",
      "\n",
      "Window 6/11: PRE+POST[0→1.0s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 1.0s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(1.0))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6930 ± 0.0134\n",
      "    F1-Score: 0.6793 ± 0.0157\n",
      "    Weights: Physio=0.038, Behavior=0.959, Gaze=0.002\n",
      "\n",
      "Window 7/11: PRE+POST[0→1.2s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 1.2s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(1.2000000000000002))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6937 ± 0.0134\n",
      "    F1-Score: 0.6797 ± 0.0157\n",
      "    Weights: Physio=0.040, Behavior=0.957, Gaze=0.002\n",
      "\n",
      "Window 8/11: PRE+POST[0→1.4s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 1.4s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(1.4000000000000001))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6946 ± 0.0134\n",
      "    F1-Score: 0.6807 ± 0.0157\n",
      "    Weights: Physio=0.038, Behavior=0.959, Gaze=0.002\n",
      "\n",
      "Window 9/11: PRE+POST[0→1.6s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 1.6s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(1.6))...\n",
      "    Extracted 11467 POST trials\n",
      "    Merged to 12511 trials with both PRE and POST\n",
      "  Using PRE+POST features: 13 PRE + 13 POST = 26 total\n",
      "  Feature shapes: Physio=(12511, 26), Behavior=(12511, 7), Gaze=(12511, 20)\n",
      "  ✓ Accuracy: 0.6952 ± 0.0135\n",
      "    F1-Score: 0.6812 ± 0.0158\n",
      "    Weights: Physio=0.038, Behavior=0.960, Gaze=0.002\n",
      "\n",
      "Window 10/11: PRE+POST[0→1.8s]\n",
      "  PRE (-2.0 to 0.0s) + POST (0.0 to 1.8s)\n",
      "--------------------------------------------------------------------------------\n",
      "  Extracting POST features for window (0.0, np.float64(1.8))...\n"
     ]
    }
   ],
   "source": [
    "rolling_results = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RUNNING ROLLING WINDOW ANALYSIS (DYNAMIC)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for i, window in enumerate(windows):\n",
    "    print(f\"\\nWindow {i+1}/{len(windows)}: {window['name']}\")\n",
    "    print(f\"  {window['description']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Prepare feature matrix\n",
    "    if window['post_window'] is None:\n",
    "        # PRE only - use pre_df directly\n",
    "        combined_df = pre_df.copy()\n",
    "        \n",
    "        X_physio = SimpleImputer(strategy='mean').fit_transform(combined_df[pre_physio_cols])\n",
    "        X_behavior = SimpleImputer(strategy='mean').fit_transform(combined_df[pre_behavior_cols])\n",
    "        X_gaze = SimpleImputer(strategy='mean').fit_transform(combined_df[pre_gaze_cols])\n",
    "        \n",
    "        print(f\"  Using PRE features only: {len(pre_physio_cols)} physio\")\n",
    "        \n",
    "    else:\n",
    "        # PRE + POST - dynamically extract POST features\n",
    "        print(f\"  Extracting POST features for window {window['post_window']}...\")\n",
    "        post_df_window = extract_post_physio_for_window(window['post_window'])\n",
    "        print(f\"    Extracted {len(post_df_window)} POST trials\")\n",
    "        \n",
    "        # Merge PRE and window-specific POST\n",
    "        combined_df = pre_df.merge(\n",
    "            post_df_window,\n",
    "            on=['trial_id', 'subject_id'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        print(f\"    Merged to {len(combined_df)} trials with both PRE and POST\")\n",
    "        \n",
    "        # Get POST column names\n",
    "        post_physio_cols_window = [c for c in post_df_window.columns if c.endswith('_post_window')]\n",
    "        \n",
    "        # Combine PRE + POST physiology\n",
    "        combined_physio_cols = pre_physio_cols + post_physio_cols_window\n",
    "        X_physio = SimpleImputer(strategy='mean').fit_transform(combined_df[combined_physio_cols])\n",
    "        X_behavior = SimpleImputer(strategy='mean').fit_transform(combined_df[pre_behavior_cols])\n",
    "        X_gaze = SimpleImputer(strategy='mean').fit_transform(combined_df[pre_gaze_cols])\n",
    "        \n",
    "        print(f\"  Using PRE+POST features: {len(pre_physio_cols)} PRE + {len(post_physio_cols_window)} POST = {X_physio.shape[1]} total\")\n",
    "    \n",
    "    y = combined_df['outcome'].values\n",
    "    subjects = combined_df['subject_id'].values\n",
    "    \n",
    "    print(f\"  Feature shapes: Physio={X_physio.shape}, Behavior={X_behavior.shape}, Gaze={X_gaze.shape}\")\n",
    "    \n",
    "    # Run weighted late fusion\n",
    "    X_modalities = [X_physio, X_behavior, X_gaze]\n",
    "    modality_names = ['Physiology', 'Behavior', 'Gaze']\n",
    "    \n",
    "    try:\n",
    "        results = weighted_late_fusion(\n",
    "            X_modalities, y, subjects, modality_names,\n",
    "            fusion_method='weighted'\n",
    "        )\n",
    "        \n",
    "        window_result = {\n",
    "            'window_id': i,\n",
    "            'window_name': window['name'],\n",
    "            'post_end_time': window['post_window'][1] if window['post_window'] else 0.0,\n",
    "            'accuracy': results['accuracy_mean'],\n",
    "            'accuracy_sem': results['accuracy_sem'],\n",
    "            'accuracy_std': results['accuracy_std'],\n",
    "            'f1_score': results['f1_mean'],\n",
    "            'f1_sem': results['f1_sem'],\n",
    "            'physio_weight': results['weights'][0],\n",
    "            'behavior_weight': results['weights'][1],\n",
    "            'gaze_weight': results['weights'][2],\n",
    "            'n_subjects': results['n_subjects'],\n",
    "            'n_trials': results['n_trials'],\n",
    "            'n_physio_features': X_physio.shape[1],\n",
    "            'invest_ratio': np.mean(y)\n",
    "        }\n",
    "        \n",
    "        rolling_results.append(window_result)\n",
    "        \n",
    "        print(f\"  ✓ Accuracy: {results['accuracy_mean']:.4f} ± {results['accuracy_sem']:.4f}\")\n",
    "        print(f\"    F1-Score: {results['f1_mean']:.4f} ± {results['f1_sem']:.4f}\")\n",
    "        print(f\"    Weights: Physio={results['weights'][0]:.3f}, Behavior={results['weights'][1]:.3f}, Gaze={results['weights'][2]:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "results_df = pd.DataFrame(rolling_results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Analysis complete: {len(results_df)} windows analyzed\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Rolling Window Analysis: PRE → POST Decision Period (Dynamic)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Subplot 1: Accuracy over time\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(results_df['post_end_time'], results_df['accuracy'], \n",
    "         marker='o', linewidth=2, markersize=6, color='#2E86AB', label='Accuracy')\n",
    "ax1.fill_between(results_df['post_end_time'],\n",
    "                  results_df['accuracy'] - results_df['accuracy_sem'],\n",
    "                  results_df['accuracy'] + results_df['accuracy_sem'],\n",
    "                  alpha=0.2, color='#2E86AB')\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='Chance')\n",
    "ax1.axvline(x=0.0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Decision Point')\n",
    "ax1.set_xlabel('POST-Decision End Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('A. Model Accuracy vs. POST Window Extension', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: F1-Score over time\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(results_df['post_end_time'], results_df['f1_score'], \n",
    "         marker='s', linewidth=2, markersize=6, color='#A23B72', label='F1-Score')\n",
    "ax2.fill_between(results_df['post_end_time'],\n",
    "                  results_df['f1_score'] - results_df['f1_sem'],\n",
    "                  results_df['f1_score'] + results_df['f1_sem'],\n",
    "                  alpha=0.2, color='#A23B72')\n",
    "ax2.axvline(x=0.0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Decision Point')\n",
    "ax2.set_xlabel('POST-Decision End Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('F1-Score', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('B. F1-Score vs. POST Window Extension', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='best')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: Modality weights over time\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(results_df['post_end_time'], results_df['physio_weight'], \n",
    "         marker='o', linewidth=2, markersize=6, label='Physiology', color='#F18F01')\n",
    "ax3.plot(results_df['post_end_time'], results_df['behavior_weight'], \n",
    "         marker='s', linewidth=2, markersize=6, label='Behavior', color='#6A994E')\n",
    "ax3.plot(results_df['post_end_time'], results_df['gaze_weight'], \n",
    "         marker='^', linewidth=2, markersize=6, label='Gaze', color='#BC4B51')\n",
    "ax3.axvline(x=0.0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Decision Point')\n",
    "ax3.set_xlabel('POST-Decision End Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Modality Weight', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('C. Modality Contributions Over Time', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='best')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim([-0.05, 1.05])\n",
    "\n",
    "# Subplot 4: Number of physio features over time\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(results_df['post_end_time'], results_df['n_physio_features'], \n",
    "         marker='D', linewidth=2, markersize=6, color='#8338EC', label='Physio Features')\n",
    "ax4.axvline(x=0.0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Decision Point')\n",
    "ax4.set_xlabel('POST-Decision End Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Number of Physiology Features', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('D. Feature Count per Window', fontsize=12, fontweight='bold')\n",
    "ax4.legend(loc='best')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Compare PRE-only vs. best POST window\n",
    "pre_only_acc = results_df.iloc[0]['accuracy']\n",
    "pre_only_sem = results_df.iloc[0]['accuracy_sem']\n",
    "\n",
    "best_idx = results_df['accuracy'].idxmax()\n",
    "best_window = results_df.iloc[best_idx]\n",
    "\n",
    "print(\"1. PRE-only vs. Best POST Window:\")\n",
    "print(f\"   PRE-only:      Accuracy = {pre_only_acc:.4f} ± {pre_only_sem:.4f}\")\n",
    "print(f\"   Best window:   {best_window['window_name']}\")\n",
    "print(f\"                  Accuracy = {best_window['accuracy']:.4f} ± {best_window['accuracy_sem']:.4f}\")\n",
    "print(f\"   Improvement:   {(best_window['accuracy'] - pre_only_acc):.4f} ({100*(best_window['accuracy'] - pre_only_acc)/pre_only_acc:.2f}%)\")\n",
    "\n",
    "# Trend analysis\n",
    "if len(results_df) > 2:\n",
    "    post_times = results_df['post_end_time'].values[1:]\n",
    "    post_accs = results_df['accuracy'].values[1:]\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "    r, p = pearsonr(post_times, post_accs)\n",
    "    \n",
    "    print(f\"\\n2. Trend Analysis (POST windows):\")\n",
    "    print(f\"   Pearson r = {r:.4f}, p = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        trend = \"positive\" if r > 0 else \"negative\"\n",
    "        print(f\"   ✓ Significant {trend} trend detected\")\n",
    "    else:\n",
    "        print(f\"   ✗ No significant trend\")\n",
    "\n",
    "print(f\"\\n3. Summary:\")\n",
    "print(f\"   Accuracy range: {results_df['accuracy'].min():.4f} to {results_df['accuracy'].max():.4f}\")\n",
    "print(f\"   Variability: {results_df['accuracy'].std():.4f}\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('../../data/results/analysis_outputs_PRE')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / 'rolling_window_post_decision_dynamic.csv'\n",
    "save_results(results_df, str(output_file))\n",
    "\n",
    "print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
