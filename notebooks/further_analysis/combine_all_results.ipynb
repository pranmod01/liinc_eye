{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All Analysis Results\n",
    "\n",
    "This notebook consolidates all analysis results into a single comprehensive dataframe:\n",
    "1. Late fusion model results (PRE/POST)\n",
    "2. Ambiguity group analysis (balanced/unbalanced)\n",
    "3. Reaction time group analysis (balanced/unbalanced)\n",
    "4. Statistical testing results\n",
    "5. Feature importance (SHAP) results\n",
    "6. Rolling window analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Base paths\n",
    "BASE_PATH = Path('../../data/results')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_fusion_results(time_period):\n",
    "    \"\"\"Load late fusion model results for PRE or POST.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    # Method comparison\n",
    "    comp_file = path / f'late_fusion_model_{time_period}_method_comparison.csv'\n",
    "    if comp_file.exists():\n",
    "        df = pd.read_csv(comp_file)\n",
    "        df['analysis_type'] = 'late_fusion'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = comp_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Subject accuracies\n",
    "    subj_file = path / f'late_fusion_model_{time_period}_subject_accuracies.csv'\n",
    "    if subj_file.exists():\n",
    "        df = pd.read_csv(subj_file)\n",
    "        df['analysis_type'] = 'late_fusion_subject'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = subj_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Modality weights\n",
    "    weight_file = path / f'late_fusion_model_{time_period}_modality_weights.csv'\n",
    "    if weight_file.exists():\n",
    "        df = pd.read_csv(weight_file)\n",
    "        df['analysis_type'] = 'modality_weights'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = weight_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Visit-based analysis\n",
    "    visit_file = path / f'late_fusion_by_visit_{time_period}_comparison.csv'\n",
    "    if visit_file.exists():\n",
    "        df = pd.read_csv(visit_file)\n",
    "        df['analysis_type'] = 'late_fusion_by_visit'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = visit_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_ambiguity_results(time_period, balanced=False):\n",
    "    \"\"\"Load ambiguity group analysis results.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    balance_str = '_balanced' if balanced else ''\n",
    "    results = []\n",
    "\n",
    "    for group in ['Low', 'Medium', 'High']:\n",
    "        # Comparison file\n",
    "        comp_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_comparison.csv'\n",
    "        if comp_file.exists():\n",
    "            df = pd.read_csv(comp_file)\n",
    "            df['analysis_type'] = 'ambiguity_group'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = comp_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Subject accuracies\n",
    "        subj_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_subject_accuracies.csv'\n",
    "        if subj_file.exists():\n",
    "            df = pd.read_csv(subj_file)\n",
    "            df['analysis_type'] = 'ambiguity_group_subject'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = subj_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Weights\n",
    "        weight_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_weights.csv'\n",
    "        if weight_file.exists():\n",
    "            df = pd.read_csv(weight_file)\n",
    "            df['analysis_type'] = 'ambiguity_group_weights'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = weight_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_rt_results(time_period, balanced=False):\n",
    "    \"\"\"Load reaction time group analysis results.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    balance_str = '_balanced' if balanced else ''\n",
    "    results = []\n",
    "\n",
    "    for group in ['Fast', 'Slow']:\n",
    "        # Comparison file\n",
    "        comp_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_comparison.csv'\n",
    "        if comp_file.exists():\n",
    "            df = pd.read_csv(comp_file)\n",
    "            df['analysis_type'] = 'reaction_time_group'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = comp_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Subject accuracies\n",
    "        subj_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_subject_accuracies.csv'\n",
    "        if subj_file.exists():\n",
    "            df = pd.read_csv(subj_file)\n",
    "            df['analysis_type'] = 'reaction_time_group_subject'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = subj_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Weights\n",
    "        weight_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_weights.csv'\n",
    "        if weight_file.exists():\n",
    "            df = pd.read_csv(weight_file)\n",
    "            df['analysis_type'] = 'reaction_time_group_weights'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = weight_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_statistical_results(time_period):\n",
    "    \"\"\"Load statistical testing results.\"\"\"\n",
    "    path = BASE_PATH / f'analysis_outputs_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    # McNemar's test summary\n",
    "    mcnemar_file = path / f'mcnemar_test_summary_{time_period}.csv'\n",
    "    if mcnemar_file.exists():\n",
    "        df = pd.read_csv(mcnemar_file)\n",
    "        df['analysis_type'] = 'mcnemar_test'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'balanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = mcnemar_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Comprehensive statistical summary\n",
    "    stat_file = path / f'statistical_testing_summary_{time_period}.csv'\n",
    "    if stat_file.exists():\n",
    "        df = pd.read_csv(stat_file)\n",
    "        df['analysis_type'] = 'statistical_summary'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'balanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = stat_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_shap_results(time_period):\n",
    "    \"\"\"Load SHAP feature importance results.\"\"\"\n",
    "    path = BASE_PATH / f'analysis_outputs_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    modalities = ['all', 'behavior', 'gaze', 'physiology', 'combined', 'phys_gaze']\n",
    "\n",
    "    for modality in modalities:\n",
    "        shap_file = path / f'shap_importance_{modality}_{time_period}.csv'\n",
    "        if shap_file.exists():\n",
    "            df = pd.read_csv(shap_file)\n",
    "            df['analysis_type'] = f'shap_{modality}'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'na'\n",
    "            df['subgroup'] = 'none'\n",
    "            df['file_source'] = shap_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_rolling_window_results():\n",
    "    \"\"\"Load rolling window post-decision analysis results.\"\"\"\n",
    "    path = BASE_PATH / 'fusion_model_results_POST'\n",
    "    results = []\n",
    "\n",
    "    # Summary\n",
    "    summary_file = path / 'rolling_window_post_decision_summary.csv'\n",
    "    if summary_file.exists():\n",
    "        df = pd.read_csv(summary_file)\n",
    "        df['analysis_type'] = 'rolling_window_summary'\n",
    "        df['time_period'] = 'POST_rolling'\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = summary_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Detailed analysis\n",
    "    detail_file = path / 'rolling_window_post_decision_analysis.csv'\n",
    "    if detail_file.exists():\n",
    "        df = pd.read_csv(detail_file)\n",
    "        df['analysis_type'] = 'rolling_window_detailed'\n",
    "        df['time_period'] = 'POST_rolling'\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = detail_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMBINING ALL ANALYSIS RESULTS\n",
      "======================================================================\n",
      "\n",
      "1. Loading late fusion results...\n",
      "   ✓ Loaded 4 files for PRE\n",
      "   ✓ Loaded 4 files for POST\n",
      "\n",
      "2. Loading ambiguity group results...\n",
      "   ✓ Loaded 6 files for PRE (unbalanced)\n",
      "   ✓ Loaded 6 files for PRE (balanced)\n",
      "   ✓ Loaded 6 files for POST (unbalanced)\n",
      "   ✓ Loaded 6 files for POST (balanced)\n",
      "\n",
      "3. Loading reaction time group results...\n",
      "   ✓ Loaded 4 files for PRE (unbalanced)\n",
      "   ✓ Loaded 4 files for PRE (balanced)\n",
      "   ✓ Loaded 4 files for POST (unbalanced)\n",
      "   ✓ Loaded 4 files for POST (balanced)\n",
      "\n",
      "4. Loading statistical testing results...\n",
      "   ✓ Loaded 2 files for PRE\n",
      "   ✓ Loaded 2 files for POST\n",
      "\n",
      "5. Loading SHAP feature importance results...\n",
      "   ✓ Loaded 6 files for PRE\n",
      "   ✓ Loaded 0 files for POST\n",
      "\n",
      "6. Loading rolling window results...\n",
      "   ✓ Loaded 0 files\n",
      "\n",
      "======================================================================\n",
      "Total dataframes loaded: 58\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMBINING ALL ANALYSIS RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# 1. Late fusion results\n",
    "print(\"\\n1. Loading late fusion results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_fusion_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 2. Ambiguity group results\n",
    "print(\"\\n2. Loading ambiguity group results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    for balanced in [False, True]:\n",
    "        results = load_ambiguity_results(time_period, balanced)\n",
    "        all_results.extend(results)\n",
    "        balance_str = 'balanced' if balanced else 'unbalanced'\n",
    "        print(f\"   ✓ Loaded {len(results)} files for {time_period} ({balance_str})\")\n",
    "\n",
    "# 3. Reaction time group results\n",
    "print(\"\\n3. Loading reaction time group results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    for balanced in [False, True]:\n",
    "        results = load_rt_results(time_period, balanced)\n",
    "        all_results.extend(results)\n",
    "        balance_str = 'balanced' if balanced else 'unbalanced'\n",
    "        print(f\"   ✓ Loaded {len(results)} files for {time_period} ({balance_str})\")\n",
    "\n",
    "# 4. Statistical testing results\n",
    "print(\"\\n4. Loading statistical testing results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_statistical_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 5. SHAP feature importance\n",
    "print(\"\\n5. Loading SHAP feature importance results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_shap_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 6. Rolling window results\n",
    "print(\"\\n6. Loading rolling window results...\")\n",
    "results = load_rolling_window_results()\n",
    "all_results.extend(results)\n",
    "print(f\"   ✓ Loaded {len(results)} files\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Total dataframes loaded: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Combined dataframe shape: (2416, 33)\n",
      "\n",
      "Analysis types included:\n",
      "  - ambiguity_group_subject: 1164 rows\n",
      "  - ambiguity_group_weights: 36 rows\n",
      "  - late_fusion: 12 rows\n",
      "  - late_fusion_by_visit: 6 rows\n",
      "  - late_fusion_subject: 194 rows\n",
      "  - mcnemar_test: 20 rows\n",
      "  - modality_weights: 6 rows\n",
      "  - reaction_time_group_subject: 776 rows\n",
      "  - reaction_time_group_weights: 24 rows\n",
      "  - shap_all: 40 rows\n",
      "  - shap_behavior: 7 rows\n",
      "  - shap_combined: 33 rows\n",
      "  - shap_gaze: 20 rows\n",
      "  - shap_phys_gaze: 33 rows\n",
      "  - shap_physiology: 13 rows\n",
      "  - statistical_summary: 32 rows\n",
      "\n",
      "======================================================================\n",
      "✓ SAVED: ../../data/results/combined_all_results.csv\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(all_results, ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"✓ Combined dataframe shape: {combined_df.shape}\")\n",
    "print(f\"\\nAnalysis types included:\")\n",
    "for analysis_type in sorted(combined_df['analysis_type'].unique()):\n",
    "    count = (combined_df['analysis_type'] == analysis_type).sum()\n",
    "    print(f\"  - {analysis_type}: {count} rows\")\n",
    "\n",
    "# Save combined results\n",
    "output_file = BASE_PATH / 'combined_all_results.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ SAVED: {output_file}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY BY DIMENSIONS:\n",
      "\n",
      "1. Analysis Types: 16\n",
      "   ['ambiguity_group_subject', 'ambiguity_group_weights', 'late_fusion', 'late_fusion_by_visit', 'late_fusion_subject', 'mcnemar_test', 'modality_weights', 'reaction_time_group_subject', 'reaction_time_group_weights', 'shap_all', 'shap_behavior', 'shap_combined', 'shap_gaze', 'shap_phys_gaze', 'shap_physiology', 'statistical_summary']\n",
      "\n",
      "2. Time Periods: 2\n",
      "   ['POST', 'PRE']\n",
      "\n",
      "3. Class Weighting: 3\n",
      "   ['balanced', 'na', 'unbalanced']\n",
      "\n",
      "4. Subgroups: 6\n",
      "   ['Fast', 'High', 'Low', 'Medium', 'Slow', 'none']\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\nSUMMARY BY DIMENSIONS:\")\n",
    "print(f\"\\n1. Analysis Types: {combined_df['analysis_type'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['analysis_type'].unique())}\")\n",
    "\n",
    "print(f\"\\n2. Time Periods: {combined_df['time_period'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['time_period'].unique())}\")\n",
    "\n",
    "print(f\"\\n3. Class Weighting: {combined_df['class_weighting'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['class_weighting'].unique())}\")\n",
    "\n",
    "print(f\"\\n4. Subgroups: {combined_df['subgroup'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['subgroup'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pivot Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING PIVOT SUMMARY...\n",
      "======================================================================\n",
      "\n",
      "✓ SAVED SUMMARY: ../../data/results/combined_results_summary.csv\n",
      "\n",
      "              analysis_type  n_rows time_periods      class_weighting         subgroups  n_files\n",
      "    ambiguity_group_subject    1164    POST, PRE balanced, unbalanced High, Low, Medium       12\n",
      "    ambiguity_group_weights      36    POST, PRE balanced, unbalanced High, Low, Medium       12\n",
      "                late_fusion      12    POST, PRE           unbalanced              none        2\n",
      "       late_fusion_by_visit       6    POST, PRE           unbalanced              none        2\n",
      "        late_fusion_subject     194    POST, PRE           unbalanced              none        2\n",
      "               mcnemar_test      20    POST, PRE             balanced              none        2\n",
      "           modality_weights       6    POST, PRE           unbalanced              none        2\n",
      "reaction_time_group_subject     776    POST, PRE balanced, unbalanced        Fast, Slow        8\n",
      "reaction_time_group_weights      24    POST, PRE balanced, unbalanced        Fast, Slow        8\n",
      "                   shap_all      40          PRE                   na              none        1\n",
      "              shap_behavior       7          PRE                   na              none        1\n",
      "              shap_combined      33          PRE                   na              none        1\n",
      "                  shap_gaze      20          PRE                   na              none        1\n",
      "             shap_phys_gaze      33          PRE                   na              none        1\n",
      "            shap_physiology      13          PRE                   na              none        1\n",
      "        statistical_summary      32    POST, PRE             balanced              none        2\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING PIVOT SUMMARY...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create summary by analysis type\n",
    "summary_data = []\n",
    "\n",
    "for analysis_type in sorted(combined_df['analysis_type'].unique()):\n",
    "    subset = combined_df[combined_df['analysis_type'] == analysis_type]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'analysis_type': analysis_type,\n",
    "        'n_rows': len(subset),\n",
    "        'time_periods': ', '.join(sorted(subset['time_period'].unique())),\n",
    "        'class_weighting': ', '.join(sorted(subset['class_weighting'].unique())),\n",
    "        'subgroups': ', '.join(sorted(subset['subgroup'].unique())),\n",
    "        'n_files': subset['file_source'].nunique()\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_file = BASE_PATH / 'combined_results_summary.csv'\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ SAVED SUMMARY: {summary_file}\")\n",
    "print(\"\\n\" + summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample of Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of combined data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>analysis_type</th>\n",
       "      <th>time_period</th>\n",
       "      <th>class_weighting</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>file_source</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>Accuracy_1</th>\n",
       "      <th>Accuracy_2</th>\n",
       "      <th>Difference</th>\n",
       "      <th>p_value</th>\n",
       "      <th>Significant</th>\n",
       "      <th>Test</th>\n",
       "      <th>Result</th>\n",
       "      <th>Interpretation</th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physiology Only</td>\n",
       "      <td>0.519080</td>\n",
       "      <td>0.504044</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behavior Only</td>\n",
       "      <td>0.647486</td>\n",
       "      <td>0.660967</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaze Only</td>\n",
       "      <td>0.502747</td>\n",
       "      <td>0.504944</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average Fusion</td>\n",
       "      <td>0.638032</td>\n",
       "      <td>0.639036</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weighted Fusion</td>\n",
       "      <td>0.693054</td>\n",
       "      <td>0.679360</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shap_phys_gaze</td>\n",
       "      <td>PRE</td>\n",
       "      <td>na</td>\n",
       "      <td>none</td>\n",
       "      <td>shap_importance_phys_gaze_PRE.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gaze_velocity_mean</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shap_phys_gaze</td>\n",
       "      <td>PRE</td>\n",
       "      <td>na</td>\n",
       "      <td>none</td>\n",
       "      <td>shap_importance_phys_gaze_PRE.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fixation_ratio</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shap_phys_gaze</td>\n",
       "      <td>PRE</td>\n",
       "      <td>na</td>\n",
       "      <td>none</td>\n",
       "      <td>shap_importance_phys_gaze_PRE.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saccade_ratio</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shap_phys_gaze</td>\n",
       "      <td>PRE</td>\n",
       "      <td>na</td>\n",
       "      <td>none</td>\n",
       "      <td>shap_importance_phys_gaze_PRE.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saccade_count</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shap_phys_gaze</td>\n",
       "      <td>PRE</td>\n",
       "      <td>na</td>\n",
       "      <td>none</td>\n",
       "      <td>shap_importance_phys_gaze_PRE.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gaze_valid_pct</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2416 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Method  Accuracy  F1-Score   analysis_type time_period  \\\n",
       "0     Physiology Only  0.519080  0.504044     late_fusion         PRE   \n",
       "1       Behavior Only  0.647486  0.660967     late_fusion         PRE   \n",
       "2           Gaze Only  0.502747  0.504944     late_fusion         PRE   \n",
       "3      Average Fusion  0.638032  0.639036     late_fusion         PRE   \n",
       "4     Weighted Fusion  0.693054  0.679360     late_fusion         PRE   \n",
       "...               ...       ...       ...             ...         ...   \n",
       "2411              NaN       NaN       NaN  shap_phys_gaze         PRE   \n",
       "2412              NaN       NaN       NaN  shap_phys_gaze         PRE   \n",
       "2413              NaN       NaN       NaN  shap_phys_gaze         PRE   \n",
       "2414              NaN       NaN       NaN  shap_phys_gaze         PRE   \n",
       "2415              NaN       NaN       NaN  shap_phys_gaze         PRE   \n",
       "\n",
       "     class_weighting subgroup                                  file_source  \\\n",
       "0         unbalanced     none  late_fusion_model_PRE_method_comparison.csv   \n",
       "1         unbalanced     none  late_fusion_model_PRE_method_comparison.csv   \n",
       "2         unbalanced     none  late_fusion_model_PRE_method_comparison.csv   \n",
       "3         unbalanced     none  late_fusion_model_PRE_method_comparison.csv   \n",
       "4         unbalanced     none  late_fusion_model_PRE_method_comparison.csv   \n",
       "...              ...      ...                                          ...   \n",
       "2411              na     none            shap_importance_phys_gaze_PRE.csv   \n",
       "2412              na     none            shap_importance_phys_gaze_PRE.csv   \n",
       "2413              na     none            shap_importance_phys_gaze_PRE.csv   \n",
       "2414              na     none            shap_importance_phys_gaze_PRE.csv   \n",
       "2415              na     none            shap_importance_phys_gaze_PRE.csv   \n",
       "\n",
       "     subject_id  accuracy  ... Accuracy_1  Accuracy_2  Difference  p_value  \\\n",
       "0           NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "1           NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "2           NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "3           NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "4           NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "...         ...       ...  ...        ...         ...         ...      ...   \n",
       "2411        NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "2412        NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "2413        NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "2414        NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "2415        NaN       NaN  ...        NaN         NaN         NaN      NaN   \n",
       "\n",
       "      Significant  Test  Result  Interpretation             feature  \\\n",
       "0             NaN   NaN     NaN             NaN                 NaN   \n",
       "1             NaN   NaN     NaN             NaN                 NaN   \n",
       "2             NaN   NaN     NaN             NaN                 NaN   \n",
       "3             NaN   NaN     NaN             NaN                 NaN   \n",
       "4             NaN   NaN     NaN             NaN                 NaN   \n",
       "...           ...   ...     ...             ...                 ...   \n",
       "2411          NaN   NaN     NaN             NaN  gaze_velocity_mean   \n",
       "2412          NaN   NaN     NaN             NaN      fixation_ratio   \n",
       "2413          NaN   NaN     NaN             NaN       saccade_ratio   \n",
       "2414          NaN   NaN     NaN             NaN       saccade_count   \n",
       "2415          NaN   NaN     NaN             NaN      gaze_valid_pct   \n",
       "\n",
       "      mean_abs_shap  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "2411       0.000783  \n",
       "2412       0.000233  \n",
       "2413       0.000182  \n",
       "2414       0.000080  \n",
       "2415       0.000000  \n",
       "\n",
       "[2416 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(\"\\nFirst 10 rows of combined data:\")\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in combined dataset:\n",
      "['Method', 'Accuracy', 'F1-Score', 'analysis_type', 'time_period', 'class_weighting', 'subgroup', 'file_source', 'subject_id', 'accuracy', 'Modality', 'Average', 'Weighted', 'Stacking', 'Visit', 'N_subjects', 'N_trials', 'F1_Score', 'Mean_Subject_Acc', 'Std_Subject_Acc', 'f1_score', 'Weight', 'Comparison', 'Accuracy_1', 'Accuracy_2', 'Difference', 'p_value', 'Significant', 'Test', 'Result', 'Interpretation', 'feature', 'mean_abs_shap']\n"
     ]
    }
   ],
   "source": [
    "# Show column names\n",
    "print(\"\\nColumns in combined dataset:\")\n",
    "print(combined_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
