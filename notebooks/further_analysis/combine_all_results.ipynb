{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All Analysis Results\n",
    "\n",
    "This notebook consolidates all analysis results into a single comprehensive dataframe:\n",
    "1. Late fusion model results (PRE/POST)\n",
    "2. Ambiguity group analysis (balanced/unbalanced)\n",
    "3. Reaction time group analysis (balanced/unbalanced)\n",
    "4. Statistical testing results\n",
    "5. Feature importance (SHAP) results\n",
    "6. Rolling window analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Base paths\n",
    "BASE_PATH = Path('../../data/results')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_fusion_results(time_period):\n",
    "    \"\"\"Load late fusion model results for PRE or POST.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    # Method comparison\n",
    "    comp_file = path / f'late_fusion_model_{time_period}_method_comparison.csv'\n",
    "    if comp_file.exists():\n",
    "        df = pd.read_csv(comp_file)\n",
    "        df['analysis_type'] = 'late_fusion'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = comp_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Subject accuracies\n",
    "    subj_file = path / f'late_fusion_model_{time_period}_subject_accuracies.csv'\n",
    "    if subj_file.exists():\n",
    "        df = pd.read_csv(subj_file)\n",
    "        df['analysis_type'] = 'late_fusion_subject'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = subj_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Modality weights\n",
    "    weight_file = path / f'late_fusion_model_{time_period}_modality_weights.csv'\n",
    "    if weight_file.exists():\n",
    "        df = pd.read_csv(weight_file)\n",
    "        df['analysis_type'] = 'modality_weights'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = weight_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Visit-based analysis\n",
    "    visit_file = path / f'late_fusion_by_visit_{time_period}_comparison.csv'\n",
    "    if visit_file.exists():\n",
    "        df = pd.read_csv(visit_file)\n",
    "        df['analysis_type'] = 'late_fusion_by_visit'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = visit_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_ambiguity_results(time_period, balanced=False):\n",
    "    \"\"\"Load ambiguity group analysis results.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    balance_str = '_balanced' if balanced else ''\n",
    "    results = []\n",
    "\n",
    "    for group in ['Low', 'Medium', 'High']:\n",
    "        # Comparison file\n",
    "        comp_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_comparison.csv'\n",
    "        if comp_file.exists():\n",
    "            df = pd.read_csv(comp_file)\n",
    "            df['analysis_type'] = 'ambiguity_group'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = comp_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Subject accuracies\n",
    "        subj_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_subject_accuracies.csv'\n",
    "        if subj_file.exists():\n",
    "            df = pd.read_csv(subj_file)\n",
    "            df['analysis_type'] = 'ambiguity_group_subject'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = subj_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Weights\n",
    "        weight_file = path / f'ambiguity_group_late_fusion{balance_str}_{time_period}_{group}_weights.csv'\n",
    "        if weight_file.exists():\n",
    "            df = pd.read_csv(weight_file)\n",
    "            df['analysis_type'] = 'ambiguity_group_weights'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = weight_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_rt_results(time_period, balanced=False):\n",
    "    \"\"\"Load reaction time group analysis results.\"\"\"\n",
    "    path = BASE_PATH / f'fusion_model_results_{time_period}'\n",
    "    balance_str = '_balanced' if balanced else ''\n",
    "    results = []\n",
    "\n",
    "    for group in ['Fast', 'Slow']:\n",
    "        # Comparison file\n",
    "        comp_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_comparison.csv'\n",
    "        if comp_file.exists():\n",
    "            df = pd.read_csv(comp_file)\n",
    "            df['analysis_type'] = 'reaction_time_group'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = comp_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Subject accuracies\n",
    "        subj_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_subject_accuracies.csv'\n",
    "        if subj_file.exists():\n",
    "            df = pd.read_csv(subj_file)\n",
    "            df['analysis_type'] = 'reaction_time_group_subject'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = subj_file.name\n",
    "            results.append(df)\n",
    "\n",
    "        # Weights\n",
    "        weight_file = path / f'reaction_time_group_late_fusion{balance_str}_{time_period}_{group}_weights.csv'\n",
    "        if weight_file.exists():\n",
    "            df = pd.read_csv(weight_file)\n",
    "            df['analysis_type'] = 'reaction_time_group_weights'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'balanced' if balanced else 'unbalanced'\n",
    "            df['subgroup'] = group\n",
    "            df['file_source'] = weight_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_statistical_results(time_period):\n",
    "    \"\"\"Load statistical testing results.\"\"\"\n",
    "    path = BASE_PATH / f'analysis_outputs_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    # McNemar's test summary\n",
    "    mcnemar_file = path / f'mcnemar_test_summary_{time_period}.csv'\n",
    "    if mcnemar_file.exists():\n",
    "        df = pd.read_csv(mcnemar_file)\n",
    "        df['analysis_type'] = 'mcnemar_test'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'balanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = mcnemar_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Comprehensive statistical summary\n",
    "    stat_file = path / f'statistical_testing_summary_{time_period}.csv'\n",
    "    if stat_file.exists():\n",
    "        df = pd.read_csv(stat_file)\n",
    "        df['analysis_type'] = 'statistical_summary'\n",
    "        df['time_period'] = time_period\n",
    "        df['class_weighting'] = 'balanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = stat_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_shap_results(time_period):\n",
    "    \"\"\"Load SHAP feature importance results.\"\"\"\n",
    "    path = BASE_PATH / f'analysis_outputs_{time_period}'\n",
    "    results = []\n",
    "\n",
    "    modalities = ['all', 'behavior', 'gaze', 'physiology', 'combined', 'phys_gaze']\n",
    "\n",
    "    for modality in modalities:\n",
    "        shap_file = path / f'shap_importance_{modality}_{time_period}.csv'\n",
    "        if shap_file.exists():\n",
    "            df = pd.read_csv(shap_file)\n",
    "            df['analysis_type'] = f'shap_{modality}'\n",
    "            df['time_period'] = time_period\n",
    "            df['class_weighting'] = 'na'\n",
    "            df['subgroup'] = 'none'\n",
    "            df['file_source'] = shap_file.name\n",
    "            results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_rolling_window_results():\n",
    "    \"\"\"Load rolling window post-decision analysis results.\"\"\"\n",
    "    path = BASE_PATH / 'fusion_model_results_POST'\n",
    "    results = []\n",
    "\n",
    "    # Summary\n",
    "    summary_file = path / 'rolling_window_post_decision_summary.csv'\n",
    "    if summary_file.exists():\n",
    "        df = pd.read_csv(summary_file)\n",
    "        df['analysis_type'] = 'rolling_window_summary'\n",
    "        df['time_period'] = 'POST_rolling'\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = summary_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    # Detailed analysis\n",
    "    detail_file = path / 'rolling_window_post_decision_analysis.csv'\n",
    "    if detail_file.exists():\n",
    "        df = pd.read_csv(detail_file)\n",
    "        df['analysis_type'] = 'rolling_window_detailed'\n",
    "        df['time_period'] = 'POST_rolling'\n",
    "        df['class_weighting'] = 'unbalanced'\n",
    "        df['subgroup'] = 'none'\n",
    "        df['file_source'] = detail_file.name\n",
    "        results.append(df)\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMBINING ALL ANALYSIS RESULTS\n",
      "======================================================================\n",
      "\n",
      "1. Loading late fusion results...\n",
      "   ✓ Loaded 4 files for PRE\n",
      "   ✓ Loaded 4 files for POST\n",
      "\n",
      "2. Loading ambiguity group results...\n",
      "   ✓ Loaded 6 files for PRE (unbalanced)\n",
      "   ✓ Loaded 6 files for PRE (balanced)\n",
      "   ✓ Loaded 6 files for POST (unbalanced)\n",
      "   ✓ Loaded 6 files for POST (balanced)\n",
      "\n",
      "3. Loading reaction time group results...\n",
      "   ✓ Loaded 4 files for PRE (unbalanced)\n",
      "   ✓ Loaded 4 files for PRE (balanced)\n",
      "   ✓ Loaded 4 files for POST (unbalanced)\n",
      "   ✓ Loaded 4 files for POST (balanced)\n",
      "\n",
      "4. Loading statistical testing results...\n",
      "   ✓ Loaded 0 files for PRE\n",
      "   ✓ Loaded 0 files for POST\n",
      "\n",
      "5. Loading SHAP feature importance results...\n",
      "   ✓ Loaded 6 files for PRE\n",
      "   ✓ Loaded 0 files for POST\n",
      "\n",
      "6. Loading rolling window results...\n",
      "   ✓ Loaded 0 files\n",
      "\n",
      "======================================================================\n",
      "Total dataframes loaded: 54\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMBINING ALL ANALYSIS RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# 1. Late fusion results\n",
    "print(\"\\n1. Loading late fusion results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_fusion_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 2. Ambiguity group results\n",
    "print(\"\\n2. Loading ambiguity group results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    for balanced in [False, True]:\n",
    "        results = load_ambiguity_results(time_period, balanced)\n",
    "        all_results.extend(results)\n",
    "        balance_str = 'balanced' if balanced else 'unbalanced'\n",
    "        print(f\"   ✓ Loaded {len(results)} files for {time_period} ({balance_str})\")\n",
    "\n",
    "# 3. Reaction time group results\n",
    "print(\"\\n3. Loading reaction time group results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    for balanced in [False, True]:\n",
    "        results = load_rt_results(time_period, balanced)\n",
    "        all_results.extend(results)\n",
    "        balance_str = 'balanced' if balanced else 'unbalanced'\n",
    "        print(f\"   ✓ Loaded {len(results)} files for {time_period} ({balance_str})\")\n",
    "\n",
    "# 4. Statistical testing results\n",
    "print(\"\\n4. Loading statistical testing results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_statistical_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 5. SHAP feature importance\n",
    "print(\"\\n5. Loading SHAP feature importance results...\")\n",
    "for time_period in ['PRE', 'POST']:\n",
    "    results = load_shap_results(time_period)\n",
    "    all_results.extend(results)\n",
    "    print(f\"   ✓ Loaded {len(results)} files for {time_period}\")\n",
    "\n",
    "# 6. Rolling window results\n",
    "print(\"\\n6. Loading rolling window results...\")\n",
    "results = load_rolling_window_results()\n",
    "all_results.extend(results)\n",
    "print(f\"   ✓ Loaded {len(results)} files\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Total dataframes loaded: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Combined dataframe shape: (2364, 24)\n",
      "\n",
      "Analysis types included:\n",
      "  - ambiguity_group_subject: 1164 rows\n",
      "  - ambiguity_group_weights: 36 rows\n",
      "  - late_fusion: 12 rows\n",
      "  - late_fusion_by_visit: 6 rows\n",
      "  - late_fusion_subject: 194 rows\n",
      "  - modality_weights: 6 rows\n",
      "  - reaction_time_group_subject: 776 rows\n",
      "  - reaction_time_group_weights: 24 rows\n",
      "  - shap_all: 40 rows\n",
      "  - shap_behavior: 7 rows\n",
      "  - shap_combined: 33 rows\n",
      "  - shap_gaze: 20 rows\n",
      "  - shap_phys_gaze: 33 rows\n",
      "  - shap_physiology: 13 rows\n",
      "\n",
      "======================================================================\n",
      "✓ SAVED: ../../data/results/combined_all_results.csv\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(all_results, ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"✓ Combined dataframe shape: {combined_df.shape}\")\n",
    "print(f\"\\nAnalysis types included:\")\n",
    "for analysis_type in sorted(combined_df['analysis_type'].unique()):\n",
    "    count = (combined_df['analysis_type'] == analysis_type).sum()\n",
    "    print(f\"  - {analysis_type}: {count} rows\")\n",
    "\n",
    "# Save combined results\n",
    "output_file = BASE_PATH / 'combined_all_results.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ SAVED: {output_file}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY BY DIMENSIONS:\n",
      "\n",
      "1. Analysis Types: 14\n",
      "   ['ambiguity_group_subject', 'ambiguity_group_weights', 'late_fusion', 'late_fusion_by_visit', 'late_fusion_subject', 'modality_weights', 'reaction_time_group_subject', 'reaction_time_group_weights', 'shap_all', 'shap_behavior', 'shap_combined', 'shap_gaze', 'shap_phys_gaze', 'shap_physiology']\n",
      "\n",
      "2. Time Periods: 2\n",
      "   ['POST', 'PRE']\n",
      "\n",
      "3. Class Weighting: 3\n",
      "   ['balanced', 'na', 'unbalanced']\n",
      "\n",
      "4. Subgroups: 6\n",
      "   ['Fast', 'High', 'Low', 'Medium', 'Slow', 'none']\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\nSUMMARY BY DIMENSIONS:\")\n",
    "print(f\"\\n1. Analysis Types: {combined_df['analysis_type'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['analysis_type'].unique())}\")\n",
    "\n",
    "print(f\"\\n2. Time Periods: {combined_df['time_period'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['time_period'].unique())}\")\n",
    "\n",
    "print(f\"\\n3. Class Weighting: {combined_df['class_weighting'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['class_weighting'].unique())}\")\n",
    "\n",
    "print(f\"\\n4. Subgroups: {combined_df['subgroup'].nunique()}\")\n",
    "print(f\"   {sorted(combined_df['subgroup'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pivot Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING PIVOT SUMMARY...\n",
      "======================================================================\n",
      "\n",
      "✓ SAVED SUMMARY: ../../data/results/combined_results_summary.csv\n",
      "\n",
      "              analysis_type  n_rows time_periods      class_weighting         subgroups  n_files\n",
      "    ambiguity_group_subject    1164    POST, PRE balanced, unbalanced High, Low, Medium       12\n",
      "    ambiguity_group_weights      36    POST, PRE balanced, unbalanced High, Low, Medium       12\n",
      "                late_fusion      12    POST, PRE           unbalanced              none        2\n",
      "       late_fusion_by_visit       6    POST, PRE           unbalanced              none        2\n",
      "        late_fusion_subject     194    POST, PRE           unbalanced              none        2\n",
      "           modality_weights       6    POST, PRE           unbalanced              none        2\n",
      "reaction_time_group_subject     776    POST, PRE balanced, unbalanced        Fast, Slow        8\n",
      "reaction_time_group_weights      24    POST, PRE balanced, unbalanced        Fast, Slow        8\n",
      "                   shap_all      40          PRE                   na              none        1\n",
      "              shap_behavior       7          PRE                   na              none        1\n",
      "              shap_combined      33          PRE                   na              none        1\n",
      "                  shap_gaze      20          PRE                   na              none        1\n",
      "             shap_phys_gaze      33          PRE                   na              none        1\n",
      "            shap_physiology      13          PRE                   na              none        1\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING PIVOT SUMMARY...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create summary by analysis type\n",
    "summary_data = []\n",
    "\n",
    "for analysis_type in sorted(combined_df['analysis_type'].unique()):\n",
    "    subset = combined_df[combined_df['analysis_type'] == analysis_type]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'analysis_type': analysis_type,\n",
    "        'n_rows': len(subset),\n",
    "        'time_periods': ', '.join(sorted(subset['time_period'].unique())),\n",
    "        'class_weighting': ', '.join(sorted(subset['class_weighting'].unique())),\n",
    "        'subgroups': ', '.join(sorted(subset['subgroup'].unique())),\n",
    "        'n_files': subset['file_source'].nunique()\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_file = BASE_PATH / 'combined_results_summary.csv'\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ SAVED SUMMARY: {summary_file}\")\n",
    "print(\"\\n\" + summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample of Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of combined data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>analysis_type</th>\n",
       "      <th>time_period</th>\n",
       "      <th>class_weighting</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>file_source</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>Visit</th>\n",
       "      <th>N_subjects</th>\n",
       "      <th>N_trials</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Mean_Subject_Acc</th>\n",
       "      <th>Std_Subject_Acc</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Weight</th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physiology Only</td>\n",
       "      <td>0.519080</td>\n",
       "      <td>0.504044</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behavior Only</td>\n",
       "      <td>0.647486</td>\n",
       "      <td>0.660967</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaze Only</td>\n",
       "      <td>0.502747</td>\n",
       "      <td>0.504944</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average Fusion</td>\n",
       "      <td>0.638032</td>\n",
       "      <td>0.639036</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weighted Fusion</td>\n",
       "      <td>0.693054</td>\n",
       "      <td>0.679360</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.635366</td>\n",
       "      <td>0.644421</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_method_comparison.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late_fusion_subject</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_subject_accuracies.csv</td>\n",
       "      <td>0806_1000_539136F</td>\n",
       "      <td>0.635593</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late_fusion_subject</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_subject_accuracies.csv</td>\n",
       "      <td>0806_1000_U9TEJGM</td>\n",
       "      <td>0.725191</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late_fusion_subject</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_subject_accuracies.csv</td>\n",
       "      <td>0811_1000_4LI8GO7</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late_fusion_subject</td>\n",
       "      <td>PRE</td>\n",
       "      <td>unbalanced</td>\n",
       "      <td>none</td>\n",
       "      <td>late_fusion_model_PRE_subject_accuracies.csv</td>\n",
       "      <td>0811_1000_539136F</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  Accuracy  F1-Score        analysis_type time_period  \\\n",
       "0  Physiology Only  0.519080  0.504044          late_fusion         PRE   \n",
       "1    Behavior Only  0.647486  0.660967          late_fusion         PRE   \n",
       "2        Gaze Only  0.502747  0.504944          late_fusion         PRE   \n",
       "3   Average Fusion  0.638032  0.639036          late_fusion         PRE   \n",
       "4  Weighted Fusion  0.693054  0.679360          late_fusion         PRE   \n",
       "5         Stacking  0.635366  0.644421          late_fusion         PRE   \n",
       "6              NaN       NaN       NaN  late_fusion_subject         PRE   \n",
       "7              NaN       NaN       NaN  late_fusion_subject         PRE   \n",
       "8              NaN       NaN       NaN  late_fusion_subject         PRE   \n",
       "9              NaN       NaN       NaN  late_fusion_subject         PRE   \n",
       "\n",
       "  class_weighting subgroup                                   file_source  \\\n",
       "0      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "1      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "2      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "3      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "4      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "5      unbalanced     none   late_fusion_model_PRE_method_comparison.csv   \n",
       "6      unbalanced     none  late_fusion_model_PRE_subject_accuracies.csv   \n",
       "7      unbalanced     none  late_fusion_model_PRE_subject_accuracies.csv   \n",
       "8      unbalanced     none  late_fusion_model_PRE_subject_accuracies.csv   \n",
       "9      unbalanced     none  late_fusion_model_PRE_subject_accuracies.csv   \n",
       "\n",
       "          subject_id  accuracy  ... Visit  N_subjects  N_trials  F1_Score  \\\n",
       "0                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "1                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "2                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "3                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "4                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "5                NaN       NaN  ...   NaN         NaN       NaN       NaN   \n",
       "6  0806_1000_539136F  0.635593  ...   NaN         NaN       NaN       NaN   \n",
       "7  0806_1000_U9TEJGM  0.725191  ...   NaN         NaN       NaN       NaN   \n",
       "8  0811_1000_4LI8GO7  0.595041  ...   NaN         NaN       NaN       NaN   \n",
       "9  0811_1000_539136F  0.738462  ...   NaN         NaN       NaN       NaN   \n",
       "\n",
       "   Mean_Subject_Acc  Std_Subject_Acc  f1_score  Weight  feature  mean_abs_shap  \n",
       "0               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "1               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "2               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "3               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "4               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "5               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "6               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "7               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "8               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "9               NaN              NaN       NaN     NaN      NaN            NaN  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(\"\\nFirst 10 rows of combined data:\")\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in combined dataset:\n",
      "['Method', 'Accuracy', 'F1-Score', 'analysis_type', 'time_period', 'class_weighting', 'subgroup', 'file_source', 'subject_id', 'accuracy', 'Modality', 'Average', 'Weighted', 'Stacking', 'Visit', 'N_subjects', 'N_trials', 'F1_Score', 'Mean_Subject_Acc', 'Std_Subject_Acc', 'f1_score', 'Weight', 'feature', 'mean_abs_shap']\n"
     ]
    }
   ],
   "source": [
    "# Show column names\n",
    "print(\"\\nColumns in combined dataset:\")\n",
    "print(combined_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
