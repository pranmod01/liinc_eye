{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction (PRE-Decision) - Run Once, Use Everywhere\n",
    "\n",
    "This notebook extracts all features (physiology PRE-decision, behavior, gaze) from preprocessing results and saves them to a pickle file.\n",
    "\n",
    "**PRE-DECISION: Extracts pupil features from BEFORE the submit button press (decision period)**\n",
    "\n",
    "**Run this notebook ONCE after preprocessing completes.**\n",
    "\n",
    "All other model notebooks will load the saved features instead of re-extracting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction started: 2025-12-27 14:06:32\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Feature extraction started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Physiology and Behavior Features (PRE-Decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 preprocessing files\n",
      "Baseline correction method: t3_stable_pre_decision\n"
     ]
    }
   ],
   "source": [
    "preprocessing_dir = Path('../../data/results/preprocessing_outputs/preprocessing')\n",
    "preprocessing_files = sorted(preprocessing_dir.glob('preprocessing_*.json'))\n",
    "raw_dir = Path('../../data/raw/json')\n",
    "baseline_method = 't3_stable_pre_decision'\n",
    "\n",
    "print(f\"Found {len(preprocessing_files)} preprocessing files\")\n",
    "print(f\"Baseline correction method: {baseline_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing subject: 0727_1400_539136F ✓ 0 trials\n",
      "\n",
      "Processing subject: 0727_1400_A6I5HI6 ✓ 0 trials\n",
      "\n",
      "Processing subject: 0806_1000_539136F ✓ 118 trials\n",
      "\n",
      "Processing subject: 0806_1000_U9TEJGM ✓ 131 trials\n",
      "\n",
      "Processing subject: 0811_1000_4LI8GO7 ✓ 121 trials\n",
      "\n",
      "Processing subject: 0811_1000_539136F ✓ 130 trials\n",
      "\n",
      "Processing subject: 0811_1000_U9TEJGM ✓ 131 trials\n",
      "\n",
      "Processing subject: 0813_1000_539136F ✓ 129 trials\n",
      "\n",
      "Processing subject: 0813_1000_9M4VCHG ✓ 123 trials\n",
      "\n",
      "Processing subject: 0813_1000_U9TEJGM ✓ 128 trials\n",
      "\n",
      "Processing subject: 0813_1600_539136F ✓ 124 trials\n",
      "\n",
      "Processing subject: 0813_1600_9M4VCHG ✓ 130 trials\n",
      "\n",
      "Processing subject: 0813_1600_U9TEJGM ✓ 123 trials\n",
      "\n",
      "Processing subject: 0816_1400_539136F ✓ 129 trials\n",
      "\n",
      "Processing subject: 0816_1400_9M4VCHG ✓ 124 trials\n",
      "\n",
      "Processing subject: 0816_1400_U9TEJGM ✓ 125 trials\n",
      "\n",
      "Processing subject: 0817_1000_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0817_1000_9M4VCHG ✓ 131 trials\n",
      "\n",
      "Processing subject: 0817_1000_U9TEJGM ✓ 119 trials\n",
      "\n",
      "Processing subject: 0818_1600_539136F ✓ 132 trials\n",
      "\n",
      "Processing subject: 0818_1600_9M4VCHG ✓ 90 trials\n",
      "\n",
      "Processing subject: 0818_1600_U9TEJGM ✓ 132 trials\n",
      "\n",
      "Processing subject: 0819_1400_539136F ✓ 129 trials\n",
      "\n",
      "Processing subject: 0819_1400_9M4VCHG ✓ 103 trials\n",
      "\n",
      "Processing subject: 0819_1400_U9TEJGM ✓ 129 trials\n",
      "\n",
      "Processing subject: 0823_1400_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0823_1400_9M4VCHG ✓ 132 trials\n",
      "\n",
      "Processing subject: 0823_1400_U9TEJGM ✓ 123 trials\n",
      "\n",
      "Processing subject: 0824_1000_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0824_1000_9M4VCHG ✓ 107 trials\n",
      "\n",
      "Processing subject: 0824_1000_U9TEJGM ✓ 114 trials\n",
      "\n",
      "Processing subject: 0824_1600_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0824_1600_9M4VCHG ✓ 128 trials\n",
      "\n",
      "Processing subject: 0824_1600_U9TEJGM ✓ 121 trials\n",
      "\n",
      "Processing subject: 0825_1000_539136F ✓ 37 trials\n",
      "\n",
      "Processing subject: 0825_1000_9M4VCHG ✓ 9 trials\n",
      "\n",
      "Processing subject: 0825_1300_539136F ✓ 124 trials\n",
      "\n",
      "Processing subject: 0825_1300_9M4VCHG ✓ 119 trials\n",
      "\n",
      "Processing subject: 0825_1300_U9TEJGM ✓ 89 trials\n",
      "\n",
      "Processing subject: 0826_1000_539136F ✓ 132 trials\n",
      "\n",
      "Processing subject: 0826_1000_9M4VCHG ✓ 127 trials\n",
      "\n",
      "Processing subject: 0826_1300_539136F ✓ 132 trials\n",
      "\n",
      "Processing subject: 0826_1300_9M4VCHG ✓ 121 trials\n",
      "\n",
      "Processing subject: 0826_1300_U9TEJGM ✓ 78 trials\n",
      "\n",
      "Processing subject: 0827_1000_539136F ✓ 128 trials\n",
      "\n",
      "Processing subject: 0827_1000_9M4VCHG ✓ 131 trials\n",
      "\n",
      "Processing subject: 0827_1000_U9TEJGM ✓ 122 trials\n",
      "\n",
      "Processing subject: 0828_1300_9M4VCHG ✓ 113 trials\n",
      "\n",
      "Processing subject: 0828_1300_U9TEJGM ✓ 74 trials\n",
      "\n",
      "Processing subject: 0830_1300_539136F ✓ 126 trials\n",
      "\n",
      "Processing subject: 0830_1300_9M4VCHG ✓ 131 trials\n",
      "\n",
      "Processing subject: 0830_1300_U9TEJGM ✓ 129 trials\n",
      "\n",
      "Processing subject: 0831_1000_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0831_1000_9M4VCHG ✓ 79 trials\n",
      "\n",
      "Processing subject: 0831_1000_U9TEJGM ✓ 132 trials\n",
      "\n",
      "Processing subject: 0831_1300_539136F ✓ 130 trials\n",
      "\n",
      "Processing subject: 0831_1300_9M4VCHG ✓ 119 trials\n",
      "\n",
      "Processing subject: 0831_1300_U9TEJGM ✓ 129 trials\n",
      "\n",
      "Processing subject: 0901_1000_539136F ✓ 125 trials\n",
      "\n",
      "Processing subject: 0901_1000_9M4VCHG ✓ 124 trials\n",
      "\n",
      "Processing subject: 0901_1000_U9TEJGM ✓ 132 trials\n",
      "\n",
      "Processing subject: 0901_1300_539136F ✓ 116 trials\n",
      "\n",
      "Processing subject: 0901_1300_9M4VCHG ✓ 124 trials\n",
      "\n",
      "Processing subject: 0901_1300_U9TEJGM ✓ 128 trials\n",
      "\n",
      "Processing subject: 0915_1000_539136F ✓ 119 trials\n",
      "\n",
      "Processing subject: 0915_1000_9M4VCHG ✓ 131 trials\n",
      "\n",
      "Processing subject: 0915_1000_U9TEJGM ✓ 82 trials\n",
      "\n",
      "Processing subject: 0917_1030_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0917_1030_9M4VCHG ✓ 129 trials\n",
      "\n",
      "Processing subject: 0917_1030_U9TEJGM ✓ 129 trials\n",
      "\n",
      "Processing subject: 0920_1600_539136F ✓ 128 trials\n",
      "\n",
      "Processing subject: 0920_1600_9M4VCHG ✓ 128 trials\n",
      "\n",
      "Processing subject: 0920_1600_U9TEJGM ✓ 123 trials\n",
      "\n",
      "Processing subject: 0922_1000_539136F ✓ 123 trials\n",
      "\n",
      "Processing subject: 0922_1000_9M4VCHG ✓ 129 trials\n",
      "\n",
      "Processing subject: 0922_1000_U9TEJGM ✓ 110 trials\n",
      "\n",
      "Processing subject: 0923_1000_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0923_1000_9M4VCHG ✓ 131 trials\n",
      "\n",
      "Processing subject: 0923_1000_U9TEJGM ✓ 128 trials\n",
      "\n",
      "Processing subject: 0923_1600_539136F ✓ 121 trials\n",
      "\n",
      "Processing subject: 0923_1600_9M4VCHG ✓ 130 trials\n",
      "\n",
      "Processing subject: 0923_1600_U9TEJGM ✓ 128 trials\n",
      "\n",
      "Processing subject: 0924_1000_539136F ✓ 128 trials\n",
      "\n",
      "Processing subject: 0924_1000_9M4VCHG ✓ 130 trials\n",
      "\n",
      "Processing subject: 0924_1000_U9TEJGM ✓ 120 trials\n",
      "\n",
      "Processing subject: 0924_1600_539136F ✓ 59 trials\n",
      "\n",
      "Processing subject: 0924_1600_9M4VCHG ✓ 130 trials\n",
      "\n",
      "Processing subject: 0924_1600_U9TEJGM ✓ 123 trials\n",
      "\n",
      "Processing subject: 0927_0930_539136F ✓ 131 trials\n",
      "\n",
      "Processing subject: 0927_0930_U9TEJGM ✓ 99 trials\n",
      "\n",
      "Processing subject: 0928_1600_539136F ✓ 110 trials\n",
      "\n",
      "Processing subject: 0928_1600_9M4VCHG ✓ 117 trials\n",
      "\n",
      "Processing subject: 0928_1600_U9TEJGM ✓ 93 trials\n",
      "\n",
      "Processing subject: 0930_1700_539136F ✓ 95 trials\n",
      "\n",
      "Processing subject: 0930_1700_9M4VCHG ✓ 112 trials\n",
      "\n",
      "Processing subject: 0930_1700_U9TEJGM ✓ 123 trials\n",
      "\n",
      "Processing subject: 1005_1600_539136F ✓ 121 trials\n",
      "\n",
      "Processing subject: 1005_1600_9M4VCHG ✓ 123 trials\n",
      "\n",
      "Processing subject: 1005_1600_U9TEJGM ✓ 51 trials\n",
      "\n",
      "================================================================================\n",
      "Total trials extracted: 11467\n"
     ]
    }
   ],
   "source": [
    "# Extract all features\n",
    "all_physiology_features = []\n",
    "all_behavior_features = []\n",
    "all_outcomes = []\n",
    "all_subject_ids = []\n",
    "all_trial_ids = []\n",
    "\n",
    "total_trials = 0\n",
    "\n",
    "for preprocessed_file in preprocessing_files:\n",
    "    with open(preprocessed_file, 'r') as f:\n",
    "        preprocessed = json.load(f)\n",
    "    \n",
    "    subject_id = preprocessed['subject_id']\n",
    "    print(f\"\\nProcessing subject: {subject_id}\", end=\" \")\n",
    "    \n",
    "    matches = list(raw_dir.glob(f\"*{subject_id.split('_')[-1]}.json\"))\n",
    "    pattern = subject_id.replace(\"_\", \".*\")\n",
    "    match = next((f for f in matches if re.search(pattern, f.name)), None)\n",
    "    if not match:\n",
    "        print(\"❌ No matching JSON file\")\n",
    "        continue\n",
    "    \n",
    "    with open(match, 'r') as f:\n",
    "        raw_data = json.load(f)\n",
    "    \n",
    "    subject_trial_count = 0\n",
    "    \n",
    "    for trial_id, trial_data in preprocessed['trial_data'].items():\n",
    "        method_data = trial_data['methods'][baseline_method]\n",
    "        \n",
    "        if method_data['success'] != True:\n",
    "            continue\n",
    "        \n",
    "        raw_trial = raw_data['trials'][int(trial_id)-1]\n",
    "        \n",
    "        if not raw_trial['gamble details']['submitted']:\n",
    "            continue\n",
    "        \n",
    "        # Extract pupil data\n",
    "        time_aligned = np.array(trial_data['time_relative_to_submit'])\n",
    "        pupil_avg = np.array(method_data['pupil_avg_baselined'])\n",
    "        pupil_L = np.array(method_data['pupil_L_baselined'])\n",
    "        pupil_R = np.array(method_data['pupil_R_baselined'])\n",
    "\n",
    "        valid_mask = ~np.isnan(pupil_avg)\n",
    "        pupil_avg_clean = pupil_avg[valid_mask]\n",
    "        pupil_L_clean = pupil_L[valid_mask]\n",
    "        pupil_R_clean = pupil_R[valid_mask]\n",
    "        time_clean = time_aligned[valid_mask]\n",
    "\n",
    "        if len(pupil_avg_clean) < 20:\n",
    "            continue\n",
    "\n",
    "        # PRE-SUBMIT DATA ONLY (-2 to 0 seconds before submit)\n",
    "        pre_submit_mask = (time_clean >= -2.0) & (time_clean < 0)\n",
    "        pupil_pre = pupil_avg_clean[pre_submit_mask]\n",
    "        pupil_L_pre = pupil_L_clean[pre_submit_mask]\n",
    "        pupil_R_pre = pupil_R_clean[pre_submit_mask]\n",
    "        time_pre = time_clean[pre_submit_mask]\n",
    "\n",
    "        if len(pupil_pre) < 5:\n",
    "            continue\n",
    "\n",
    "        # Calculate derivatives\n",
    "        pupil_velocity_pre = np.diff(pupil_pre) if len(pupil_pre) > 1 else np.array([0])\n",
    "        pupil_acceleration_pre = np.diff(pupil_velocity_pre) if len(pupil_velocity_pre) > 1 else np.array([0])\n",
    "        dilation_mask_pre = pupil_velocity_pre > 0 if len(pupil_velocity_pre) > 0 else np.array([False])\n",
    "\n",
    "        # PHYSIOLOGY FEATURES (PRE-SUBMIT ONLY)\n",
    "        physiology_features = {\n",
    "            'pupil_mean_pre': np.mean(pupil_pre),\n",
    "            'pupil_std_pre': np.std(pupil_pre),\n",
    "            'pupil_slope_pre': np.polyfit(time_pre, pupil_pre, 1)[0] if len(time_pre) > 1 else 0,\n",
    "            'time_to_peak_pre': time_pre[np.argmax(pupil_pre)] - time_pre[0] if len(time_pre) > 0 else 0,\n",
    "            'pupil_cv_pre': np.std(pupil_pre) / np.abs(np.mean(pupil_pre)) if (len(pupil_pre) > 0 and np.mean(pupil_pre) != 0) else 0,\n",
    "            'pupil_velocity_mean_pre': np.mean(np.abs(pupil_velocity_pre)) if len(pupil_velocity_pre) > 0 else 0,\n",
    "            'pupil_max_dilation_rate_pre': np.max(pupil_velocity_pre) if len(pupil_velocity_pre) > 0 else 0,\n",
    "            'pupil_max_constriction_rate_pre': np.abs(np.min(pupil_velocity_pre)) if len(pupil_velocity_pre) > 0 else 0,\n",
    "            'pupil_acceleration_std_pre': np.std(pupil_acceleration_pre) if len(pupil_acceleration_pre) > 1 else 0,\n",
    "            'pct_time_dilating_pre': np.mean(dilation_mask_pre) if len(dilation_mask_pre) > 0 else 0,\n",
    "            'num_dilation_peaks_pre': np.sum(np.diff(np.sign(pupil_velocity_pre)) > 0) if len(pupil_velocity_pre) > 1 else 0,\n",
    "            'eye_asymmetry_pre': np.nanmean(np.abs(pupil_L_pre - pupil_R_pre)) if len(pupil_L_pre) > 0 else 0,\n",
    "            'eye_asymmetry_std_pre': np.nanstd(pupil_L_pre - pupil_R_pre) if len(pupil_L_pre) > 1 else 0,\n",
    "        }\n",
    "        \n",
    "        # BEHAVIOR FEATURES\n",
    "        gamble_params = raw_trial['gamble details']['gamble parameters']\n",
    "        lct = raw_trial['lct']\n",
    "        \n",
    "        show_screen_time = None\n",
    "        submit_time = None\n",
    "        click_time = None\n",
    "        \n",
    "        for event in lct:\n",
    "            if 'show screen' in event['event']:\n",
    "                show_screen_time = event['time']\n",
    "            elif 'gamble clicked' in event['event']:\n",
    "                click_time = event['time']\n",
    "            elif 'submit' in event['event']:\n",
    "                submit_time = event['time']\n",
    "        \n",
    "        if show_screen_time is None or submit_time is None:\n",
    "            continue\n",
    "        \n",
    "        reaction_time = (click_time - show_screen_time) if click_time else np.nan\n",
    "        decision_time = (submit_time - show_screen_time)\n",
    "\n",
    "        invest_ev = (gamble_params['invest amount 1'] * gamble_params['invest probability 1'] + \n",
    "                    gamble_params['invest amount 2'] * gamble_params['invest probability 2'])\n",
    "        keep_ev = gamble_params['keep amount']\n",
    "        ev_difference = invest_ev - keep_ev\n",
    "\n",
    "        invest_variance = ((gamble_params['invest amount 1'] - invest_ev)**2 * gamble_params['invest probability 1'] +\n",
    "                        (gamble_params['invest amount 2'] - invest_ev)**2 * gamble_params['invest probability 2'])\n",
    "        \n",
    "        final_choice = raw_trial['gamble details']['choices'][-1]['choice'] if len(raw_trial['gamble details']['choices']) > 0 else None\n",
    "        chose_invest = 1 if final_choice == 'INVEST' else 0\n",
    "        \n",
    "        behavior_features = {\n",
    "            'reaction_time': reaction_time if not np.isnan(reaction_time) else decision_time,\n",
    "            'decision_time': decision_time,\n",
    "            'ev_difference': ev_difference,\n",
    "            'invest_variance': invest_variance,\n",
    "            'ambiguity': gamble_params['ambiguity'],\n",
    "            'condition_social': 1 if gamble_params['condition'] == 'social' else 0,\n",
    "            'risk_premium': ev_difference / np.sqrt(invest_variance) if invest_variance > 0 else 0,\n",
    "        }\n",
    "                \n",
    "        outcome = chose_invest\n",
    "        \n",
    "        all_physiology_features.append(physiology_features)\n",
    "        all_behavior_features.append(behavior_features)\n",
    "        all_outcomes.append(outcome)\n",
    "        all_subject_ids.append(subject_id)\n",
    "        all_trial_ids.append(f\"{trial_id}_{subject_id}\")\n",
    "        \n",
    "        subject_trial_count += 1\n",
    "    \n",
    "    print(f\"✓ {subject_trial_count} trials\")\n",
    "    total_trials += subject_trial_count\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total trials extracted: {total_trials}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Gaze Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gaze_features_from_trial(eye_data):\n",
    "    \"\"\"Extract gaze features from raw eye tracking data.\"\"\"\n",
    "    if not eye_data or len(eye_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    timestamps = np.array([s['time'] for s in eye_data])\n",
    "    gaze_x_L = np.array([s.get('gazeL_X', np.nan) for s in eye_data])\n",
    "    gaze_y_L = np.array([s.get('gazeL_Y', np.nan) for s in eye_data])\n",
    "    gaze_x_R = np.array([s.get('gazeR_X', np.nan) for s in eye_data])\n",
    "    gaze_y_R = np.array([s.get('gazeR_Y', np.nan) for s in eye_data])\n",
    "    \n",
    "    gaze_x = np.nanmean([gaze_x_L, gaze_x_R], axis=0)\n",
    "    gaze_y = np.nanmean([gaze_y_L, gaze_y_R], axis=0)\n",
    "    \n",
    "    screen_x_L = np.array([s.get('pupilLSensorPosL_X', np.nan) for s in eye_data])\n",
    "    screen_y_L = np.array([s.get('pupilLSensorPosL_Y', np.nan) for s in eye_data])\n",
    "    screen_x_R = np.array([s.get('pupilLSensorPosR_X', np.nan) for s in eye_data])\n",
    "    screen_y_R = np.array([s.get('pupilLSensorPosR_Y', np.nan) for s in eye_data])\n",
    "    \n",
    "    screen_x = np.nanmean([screen_x_L, screen_x_R], axis=0)\n",
    "    screen_y = np.nanmean([screen_y_L, screen_y_R], axis=0)\n",
    "    \n",
    "    valid_L = np.array([s.get('validL', 0) for s in eye_data])\n",
    "    valid_R = np.array([s.get('validR', 0) for s in eye_data])\n",
    "    \n",
    "    features = {}\n",
    "    features['gaze_valid_pct'] = np.mean((valid_L > 0) & (valid_R > 0))\n",
    "    \n",
    "    valid_mask = (valid_L > 0) & (valid_R > 0)\n",
    "    if valid_mask.sum() < 5:\n",
    "        return None\n",
    "    \n",
    "    gaze_x_valid = gaze_x[valid_mask]\n",
    "    gaze_y_valid = gaze_y[valid_mask]\n",
    "    screen_x_valid = screen_x[valid_mask]\n",
    "    screen_y_valid = screen_y[valid_mask]\n",
    "    timestamps_valid = timestamps[valid_mask]\n",
    "    \n",
    "    features['gaze_x_mean'] = np.nanmean(gaze_x_valid)\n",
    "    features['gaze_x_std'] = np.nanstd(gaze_x_valid)\n",
    "    features['gaze_y_mean'] = np.nanmean(gaze_y_valid)\n",
    "    features['gaze_y_std'] = np.nanstd(gaze_y_valid)\n",
    "    features['screen_x_mean'] = np.nanmean(screen_x_valid)\n",
    "    features['screen_x_std'] = np.nanstd(screen_x_valid)\n",
    "    features['screen_y_mean'] = np.nanmean(screen_y_valid)\n",
    "    features['screen_y_std'] = np.nanstd(screen_y_valid)\n",
    "    \n",
    "    dt = np.diff(timestamps_valid)\n",
    "    dt[dt == 0] = 1e-6\n",
    "    dx = np.diff(screen_x_valid)\n",
    "    dy = np.diff(screen_y_valid)\n",
    "    \n",
    "    velocity = np.sqrt(dx**2 + dy**2) / dt\n",
    "    features['gaze_velocity_mean'] = np.nanmean(velocity)\n",
    "    features['gaze_velocity_std'] = np.nanstd(velocity)\n",
    "    features['gaze_velocity_max'] = np.nanmax(velocity)\n",
    "    \n",
    "    acceleration = np.diff(velocity) / dt[:-1]\n",
    "    features['gaze_acceleration_mean'] = np.nanmean(np.abs(acceleration))\n",
    "    features['gaze_acceleration_std'] = np.nanstd(acceleration)\n",
    "    \n",
    "    fixation_mask = velocity < 30\n",
    "    saccade_mask = velocity > 100\n",
    "    features['fixation_ratio'] = np.mean(fixation_mask)\n",
    "    features['saccade_ratio'] = np.mean(saccade_mask)\n",
    "    features['saccade_count'] = np.sum(np.diff(saccade_mask.astype(int)) == 1)\n",
    "    \n",
    "    features['gaze_dispersion_x'] = np.nanmax(screen_x_valid) - np.nanmin(screen_x_valid)\n",
    "    features['gaze_dispersion_y'] = np.nanmax(screen_y_valid) - np.nanmin(screen_y_valid)\n",
    "    features['gaze_path_length'] = np.sum(np.sqrt(dx**2 + dy**2))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def map_subject_filename(json_filename):\n",
    "    match = re.search(r'(\\d{4})_(\\d{4})_LCT_DESKTOP-([A-Z0-9]+)', json_filename)\n",
    "    if match:\n",
    "        date1, date2, desktop_id = match.groups()\n",
    "        return f\"{date1}_{date2}_{desktop_id}\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting gaze features...\n",
      "Extracted gaze features from 15121 trials\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting gaze features...\")\n",
    "\n",
    "raw_json_files = sorted(raw_dir.glob('*.json'))\n",
    "all_gaze_data = []\n",
    "\n",
    "for file_path in raw_json_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    subject_id = map_subject_filename(file_path.name)\n",
    "    if not subject_id:\n",
    "        continue\n",
    "    \n",
    "    trials = data.get('trials', [])\n",
    "    \n",
    "    for trial_idx, trial in enumerate(trials):\n",
    "        eye_data = trial.get('eye', [])\n",
    "        if not eye_data:\n",
    "            continue\n",
    "        \n",
    "        gamble_details = trial.get('gamble details', {})\n",
    "        trial_id = str(gamble_details.get('trial', trial_idx))\n",
    "        \n",
    "        gaze_features = extract_gaze_features_from_trial(eye_data)\n",
    "        if gaze_features is None:\n",
    "            continue\n",
    "        \n",
    "        gaze_features['subject_id'] = subject_id\n",
    "        gaze_features['trial_id'] = f\"{trial_id}_{subject_id}\"\n",
    "        all_gaze_data.append(gaze_features)\n",
    "\n",
    "print(f\"Extracted gaze features from {len(all_gaze_data)} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create DataFrames and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL MERGED DATASET (PRE-DECISION):\n",
      "================================================================================\n",
      "Total trials: 12511\n",
      "Subjects: 97\n",
      "\n",
      "Feature counts:\n",
      "  Physiology (PRE): 13 features\n",
      "  Behavior: 7 features (reaction_time, decision_time, ev_difference, invest_variance, ambiguity, condition_social, risk_premium)\n",
      "  Gaze: 17 features\n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "1    8238\n",
      "0    4273\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "subject_id                          object\n",
      "trial_id                            object\n",
      "pupil_mean_pre                     float64\n",
      "pupil_std_pre                      float64\n",
      "pupil_slope_pre                    float64\n",
      "time_to_peak_pre                   float64\n",
      "pupil_cv_pre                       float64\n",
      "pupil_velocity_mean_pre            float64\n",
      "pupil_max_dilation_rate_pre        float64\n",
      "pupil_max_constriction_rate_pre    float64\n",
      "pupil_acceleration_std_pre         float64\n",
      "pct_time_dilating_pre              float64\n",
      "num_dilation_peaks_pre               int64\n",
      "eye_asymmetry_pre                  float64\n",
      "eye_asymmetry_std_pre              float64\n",
      "outcome                              int64\n",
      "reaction_time                      float64\n",
      "decision_time                      float64\n",
      "ev_difference                      float64\n",
      "invest_variance                    float64\n",
      "ambiguity                            int64\n",
      "condition_social                     int64\n",
      "risk_premium                       float64\n",
      "gaze_valid_pct                     float64\n",
      "gaze_x_mean                        float64\n",
      "gaze_x_std                         float64\n",
      "gaze_y_mean                        float64\n",
      "gaze_y_std                         float64\n",
      "screen_x_mean                      float64\n",
      "screen_x_std                       float64\n",
      "screen_y_mean                      float64\n",
      "screen_y_std                       float64\n",
      "gaze_velocity_mean                 float64\n",
      "gaze_velocity_std                  float64\n",
      "gaze_velocity_max                  float64\n",
      "gaze_acceleration_mean             float64\n",
      "gaze_acceleration_std              float64\n",
      "fixation_ratio                     float64\n",
      "saccade_ratio                      float64\n",
      "saccade_count                        int64\n",
      "gaze_dispersion_x                  float64\n",
      "gaze_dispersion_y                  float64\n",
      "gaze_path_length                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "physio_df = pd.DataFrame(all_physiology_features)\n",
    "physio_df.insert(0, 'subject_id', all_subject_ids)\n",
    "physio_df.insert(1, 'trial_id', all_trial_ids)\n",
    "physio_df['outcome'] = all_outcomes\n",
    "\n",
    "behavior_df = pd.DataFrame(all_behavior_features)\n",
    "behavior_df.insert(0, 'subject_id', all_subject_ids)\n",
    "behavior_df.insert(1, 'trial_id', all_trial_ids)\n",
    "behavior_df['outcome'] = all_outcomes\n",
    "\n",
    "gaze_df = pd.DataFrame(all_gaze_data)\n",
    "\n",
    "# Merge all modalities\n",
    "merged_df = physio_df.merge(\n",
    "    behavior_df.drop(columns=['outcome']),\n",
    "    on=['subject_id', 'trial_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "merged_df = merged_df.merge(\n",
    "    gaze_df,\n",
    "    on=['subject_id', 'trial_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL MERGED DATASET (PRE-DECISION):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total trials: {len(merged_df)}\")\n",
    "print(f\"Subjects: {merged_df['subject_id'].nunique()}\")\n",
    "print(f\"\\nFeature counts:\")\n",
    "print(f\"  Physiology (PRE): {len([c for c in merged_df.columns if c.endswith('_pre')])} features\")\n",
    "print(f\"  Behavior: 7 features (reaction_time, decision_time, ev_difference, invest_variance, ambiguity, condition_social, risk_premium)\")\n",
    "print(f\"  Gaze: {len([c for c in merged_df.columns if c.startswith('gaze_') or c.startswith('screen_')])} features\")\n",
    "print(f\"\\nOutcome distribution:\")\n",
    "print(merged_df['outcome'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save to Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "✓ PRE-decision features saved to: ../../data/results/features_PRE/extracted_features_PRE.pkl\n",
      "  File size: 9.00 MB\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save to pickle\n",
    "output_dir = Path('../../data/results/features_PRE')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / 'extracted_features_PRE.pkl'\n",
    "\n",
    "# Define feature column names\n",
    "physio_cols = [c for c in merged_df.columns if c.endswith('_pre')]\n",
    "behavior_cols = ['reaction_time', 'decision_time', 'ev_difference', \n",
    "                 'invest_variance', 'ambiguity', 'condition_social', 'risk_premium']\n",
    "gaze_cols = [c for c in merged_df.columns \n",
    "             if c.startswith('gaze_') or c.startswith('screen_') or \n",
    "             c in ['fixation_ratio', 'saccade_ratio', 'saccade_count', 'gaze_valid_pct',\n",
    "                   'gaze_dispersion_x', 'gaze_dispersion_y', 'gaze_path_length']]\n",
    "\n",
    "# Save with metadata\n",
    "feature_data = {\n",
    "    'merged_df': merged_df,\n",
    "    'physio_df': physio_df,\n",
    "    'behavior_df': behavior_df,\n",
    "    'gaze_df': gaze_df,\n",
    "    'physio_cols': physio_cols,\n",
    "    'behavior_cols': behavior_cols,\n",
    "    'gaze_cols': gaze_cols,\n",
    "    'metadata': {\n",
    "        'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'n_trials': len(merged_df),\n",
    "        'n_subjects': merged_df['subject_id'].nunique(),\n",
    "        'baseline_method': baseline_method,\n",
    "        'preprocessing_files': len(preprocessing_files),\n",
    "        'time_window': 'PRE-decision (-2 to 0 seconds before submit)'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(feature_data, f)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ PRE-decision features saved to: {output_file}\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
