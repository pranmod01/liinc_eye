{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Late Fusion by Ambiguity Groups with EEG\n",
    "\n",
    "This notebook extends the ambiguity group analysis to include EEG data.\n",
    "\n",
    "**Modalities:**\n",
    "1. Physiology (POST)\n",
    "2. Behavior\n",
    "3. Gaze\n",
    "4. EEG ← NEW\n",
    "\n",
    "**Analysis:**\n",
    "- Split trials into ambiguity groups (Low=0, Medium=3, High=6)\n",
    "- Run late fusion for each group with and without EEG\n",
    "- Compare EEG contribution across ambiguity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded features\n",
      "  Original trials: 12511\n",
      "  EEG trials: 10\n"
     ]
    }
   ],
   "source": [
    "# Load existing features",
    "with open('../../data/results/features_POST/extracted_features_POST.pkl', 'rb') as f:",
    "    feature_data = pickle.load(f)",
    "",
    "merged_df = feature_data['merged_df']",
    "physio_cols = feature_data['physio_cols']",
    "behavior_cols = feature_data['behavior_cols']",
    "gaze_cols = feature_data['gaze_cols']",
    "",
    "# Load EEG features",
    "with open('../../data/results/features_POST/eeg_features_POST.pkl', 'rb') as f:",
    "    eeg_data = pickle.load(f)",
    "",
    "eeg_features_df = eeg_data['eeg_features_df']",
    "eeg_cols = eeg_data['feature_columns']",
    "",
    "print(f\"✓ Loaded features\")",
    "print(f\"  Original trials: {len(merged_df)}\")",
    "print(f\"  EEG trials: {len(eeg_features_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/rf/b27xv8554s30yymsz5rpvw340000gn/T/ipykernel_53940/2396344670.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Merge EEG features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m merged_with_eeg = merged_df.merge(\n\u001b[32m      3\u001b[39m     eeg_features_df,\n\u001b[32m      4\u001b[39m     on=[\u001b[33m'subject_id'\u001b[39m, \u001b[33m'trial_id'\u001b[39m],\n\u001b[32m      5\u001b[39m     how=\u001b[33m'inner'\u001b[39m\n",
      "\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10855\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m     ) -> DataFrame:\n\u001b[32m  10857\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10858\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m         return merge(\n\u001b[32m  10860\u001b[39m             self,\n\u001b[32m  10861\u001b[39m             right,\n\u001b[32m  10862\u001b[39m             how=how,\n",
      "\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'subject_id'"
     ]
    }
   ],
   "source": [
    "# Merge EEG features\n",
    "merged_with_eeg = merged_df.merge(\n",
    "    eeg_features_df,\n",
    "    on=['subject_id', 'trial_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"✓ Merged data: {len(merged_with_eeg)} trials\")\n",
    "print(f\"  Subjects: {merged_with_eeg['subject_id'].nunique()}\")\n",
    "print(f\"\\nAmbiguity distribution:\")\n",
    "print(merged_with_eeg['ambiguity'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Late Fusion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_late_fusion(X_modalities, y, subjects, modality_names):\n",
    "    \"\"\"\n",
    "    Weighted late fusion using logistic regression meta-learner.\n",
    "    Returns subject-level accuracy for proper SEM calculation.\n",
    "    \"\"\"\n",
    "    logo = LeaveOneGroupOut()\n",
    "    base_models = [RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "                                          min_samples_split=10, min_samples_leaf=5, \n",
    "                                          random_state=42,\n",
    "                                          class_weight='balanced')\n",
    "                   for _ in X_modalities]\n",
    "    \n",
    "    subject_accs = {}\n",
    "    subject_f1s = {}\n",
    "    all_weights = []\n",
    "    \n",
    "    for train_idx, test_idx in logo.split(X_modalities[0], y, subjects):\n",
    "        train_probs, test_probs = [], []\n",
    "        \n",
    "        for X, model in zip(X_modalities, base_models):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            train_probs.append(model.predict_proba(X_train)[:, 1])\n",
    "            test_probs.append(model.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        train_probs = np.column_stack(train_probs)\n",
    "        test_probs = np.column_stack(test_probs)\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        meta = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        meta.fit(train_probs, y_train)\n",
    "        weights = meta.coef_[0]\n",
    "        y_pred = meta.predict(test_probs)\n",
    "        \n",
    "        test_subject = subjects[test_idx][0]\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        subject_accs[test_subject] = acc\n",
    "        subject_f1s[test_subject] = f1\n",
    "        all_weights.append(weights)\n",
    "    \n",
    "    subject_acc_values = np.array(list(subject_accs.values()))\n",
    "    subject_f1_values = np.array(list(subject_f1s.values()))\n",
    "    \n",
    "    avg_weights = np.mean(all_weights, axis=0)\n",
    "    norm_weights = np.exp(avg_weights) / np.sum(np.exp(avg_weights))\n",
    "    \n",
    "    return {\n",
    "        'accuracy_mean': np.mean(subject_acc_values),\n",
    "        'accuracy_sem': stats.sem(subject_acc_values),\n",
    "        'accuracy_std': np.std(subject_acc_values),\n",
    "        'f1_mean': np.mean(subject_f1_values),\n",
    "        'f1_sem': stats.sem(subject_f1_values),\n",
    "        'weights': norm_weights,\n",
    "        'n_trials': len(y),\n",
    "        'n_subjects': len(subject_accs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Create Ambiguity Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ambiguity groups\n",
    "merged_with_eeg['ambiguity_group'] = merged_with_eeg['ambiguity'].replace({0:'Low', 3:'Medium', 6:'High'})\n",
    "\n",
    "print(\"Ambiguity group distribution:\")\n",
    "print(merged_with_eeg['ambiguity_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Run Late Fusion for Each Ambiguity Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_names_no_eeg = ['Physiology (POST)', 'Behavior', 'Gaze']\n",
    "modality_names_with_eeg = ['Physiology (POST)', 'Behavior', 'Gaze', 'EEG']\n",
    "\n",
    "group_results_no_eeg = {}\n",
    "group_results_with_eeg = {}\n",
    "\n",
    "for group in ['Low', 'Medium', 'High']:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Ambiguity Group: {group}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    group_data = merged_with_eeg[merged_with_eeg['ambiguity_group'] == group]\n",
    "    \n",
    "    n_subjects = group_data['subject_id'].nunique()\n",
    "    print(f\"Trials: {len(group_data)}\")\n",
    "    print(f\"Subjects: {n_subjects}\")\n",
    "    print(f\"Outcome distribution: {group_data['outcome'].value_counts().to_dict()}\")\n",
    "    \n",
    "    if n_subjects < 3:\n",
    "        print(f\"⚠ Skipping - insufficient subjects\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare features\n",
    "    X_physio = SimpleImputer(strategy='mean').fit_transform(group_data[physio_cols])\n",
    "    X_behavior = SimpleImputer(strategy='mean').fit_transform(group_data[behavior_cols])\n",
    "    X_gaze = SimpleImputer(strategy='mean').fit_transform(group_data[gaze_cols])\n",
    "    X_eeg = SimpleImputer(strategy='mean').fit_transform(group_data[eeg_cols])\n",
    "    y = group_data['outcome'].values\n",
    "    subjects = group_data['subject_id'].values\n",
    "    \n",
    "    # WITHOUT EEG\n",
    "    print(f\"\\n--- WITHOUT EEG ---\")\n",
    "    X_modalities_no_eeg = [X_physio, X_behavior, X_gaze]\n",
    "    results_no_eeg = weighted_late_fusion(X_modalities_no_eeg, y, subjects, modality_names_no_eeg)\n",
    "    group_results_no_eeg[group] = results_no_eeg\n",
    "    \n",
    "    print(f\"Accuracy: {results_no_eeg['accuracy_mean']:.3f} ± {results_no_eeg['accuracy_sem']:.3f} (SEM)\")\n",
    "    print(f\"Modality Weights:\")\n",
    "    for name, w in zip(modality_names_no_eeg, results_no_eeg['weights']):\n",
    "        print(f\"  {name}: {w:.3f}\")\n",
    "    \n",
    "    # WITH EEG\n",
    "    print(f\"\\n--- WITH EEG ---\")\n",
    "    X_modalities_with_eeg = [X_physio, X_behavior, X_gaze, X_eeg]\n",
    "    results_with_eeg = weighted_late_fusion(X_modalities_with_eeg, y, subjects, modality_names_with_eeg)\n",
    "    group_results_with_eeg[group] = results_with_eeg\n",
    "    \n",
    "    print(f\"Accuracy: {results_with_eeg['accuracy_mean']:.3f} ± {results_with_eeg['accuracy_sem']:.3f} (SEM)\")\n",
    "    print(f\"Modality Weights:\")\n",
    "    for name, w in zip(modality_names_with_eeg, results_with_eeg['weights']):\n",
    "        print(f\"  {name}: {w:.3f}\")\n",
    "    \n",
    "    # EEG contribution\n",
    "    improvement = results_with_eeg['accuracy_mean'] - results_no_eeg['accuracy_mean']\n",
    "    print(f\"\\nEEG Contribution: {improvement:+.3f} ({(improvement/results_no_eeg['accuracy_mean']*100):+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Comparison Across Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "for group in ['Low', 'Medium', 'High']:\n",
    "    if group in group_results_no_eeg:\n",
    "        res_no_eeg = group_results_no_eeg[group]\n",
    "        res_with_eeg = group_results_with_eeg[group]\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Group': group,\n",
    "            'N_Trials': res_with_eeg['n_trials'],\n",
    "            'N_Subjects': res_with_eeg['n_subjects'],\n",
    "            'Acc_No_EEG': res_no_eeg['accuracy_mean'],\n",
    "            'Acc_No_EEG_SEM': res_no_eeg['accuracy_sem'],\n",
    "            'Acc_With_EEG': res_with_eeg['accuracy_mean'],\n",
    "            'Acc_With_EEG_SEM': res_with_eeg['accuracy_sem'],\n",
    "            'EEG_Improvement': res_with_eeg['accuracy_mean'] - res_no_eeg['accuracy_mean'],\n",
    "            'EEG_Weight': res_with_eeg['weights'][-1],\n",
    "            'Physio_Weight_NoEEG': res_no_eeg['weights'][0],\n",
    "            'Behavior_Weight_NoEEG': res_no_eeg['weights'][1],\n",
    "            'Gaze_Weight_NoEEG': res_no_eeg['weights'][2],\n",
    "            'Physio_Weight_WithEEG': res_with_eeg['weights'][0],\n",
    "            'Behavior_Weight_WithEEG': res_with_eeg['weights'][1],\n",
    "            'Gaze_Weight_WithEEG': res_with_eeg['weights'][2],\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON ACROSS AMBIGUITY GROUPS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df[['Group', 'N_Trials', 'Acc_No_EEG', 'Acc_With_EEG', 'EEG_Improvement', 'EEG_Weight']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison with/without EEG\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax = axes[0]\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison_df['Acc_No_EEG'], width, \n",
    "       yerr=comparison_df['Acc_No_EEG_SEM'], capsize=5,\n",
    "       label='Without EEG', color='steelblue', alpha=0.7)\n",
    "ax.bar(x + width/2, comparison_df['Acc_With_EEG'], width,\n",
    "       yerr=comparison_df['Acc_With_EEG_SEM'], capsize=5,\n",
    "       label='With EEG', color='coral', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Ambiguity Group')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy: With vs Without EEG')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Group'])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.axhline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "# EEG improvement\n",
    "ax = axes[1]\n",
    "bars = ax.bar(comparison_df['Group'], comparison_df['EEG_Improvement'], \n",
    "              color='mediumseagreen', alpha=0.7)\n",
    "ax.set_xlabel('Ambiguity Group')\n",
    "ax.set_ylabel('Accuracy Improvement')\n",
    "ax.set_title('EEG Contribution by Ambiguity')\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(comparison_df['EEG_Improvement']):\n",
    "    ax.text(i, v + 0.005, f'{v:+.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG weight by ambiguity group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.bar(comparison_df['Group'], comparison_df['EEG_Weight'], \n",
    "       color='orange', alpha=0.7)\n",
    "ax.set_xlabel('Ambiguity Group')\n",
    "ax.set_ylabel('EEG Weight in Fusion')\n",
    "ax.set_title('EEG Modality Weight by Ambiguity Level')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(comparison_df['EEG_Weight']):\n",
    "    ax.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality weights comparison (with vs without EEG)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "for idx, group in enumerate(['Low', 'Medium', 'High']):\n",
    "    # Without EEG\n",
    "    ax = axes[0, idx]\n",
    "    weights_no_eeg = [\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Physio_Weight_NoEEG'].values[0],\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Behavior_Weight_NoEEG'].values[0],\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Gaze_Weight_NoEEG'].values[0]\n",
    "    ]\n",
    "    ax.bar(modality_names_no_eeg, weights_no_eeg, color='steelblue', alpha=0.7)\n",
    "    ax.set_title(f'{group} - Without EEG')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    # With EEG\n",
    "    ax = axes[1, idx]\n",
    "    weights_with_eeg = [\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Physio_Weight_WithEEG'].values[0],\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Behavior_Weight_WithEEG'].values[0],\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'Gaze_Weight_WithEEG'].values[0],\n",
    "        comparison_df.loc[comparison_df['Group'] == group, 'EEG_Weight'].values[0]\n",
    "    ]\n",
    "    colors = ['steelblue', 'coral', 'mediumseagreen', 'orange']\n",
    "    ax.bar(modality_names_with_eeg, weights_with_eeg, color=colors, alpha=0.7)\n",
    "    ax.set_title(f'{group} - With EEG')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Modality Weights by Ambiguity Group', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: EEG CONTRIBUTION ACROSS AMBIGUITY LEVELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"\\n{row['Group']} Ambiguity:\")\n",
    "    print(f\"  Accuracy without EEG: {row['Acc_No_EEG']:.3f} ± {row['Acc_No_EEG_SEM']:.3f}\")\n",
    "    print(f\"  Accuracy with EEG:    {row['Acc_With_EEG']:.3f} ± {row['Acc_With_EEG_SEM']:.3f}\")\n",
    "    print(f\"  EEG improvement:      {row['EEG_Improvement']:+.3f} ({(row['EEG_Improvement']/row['Acc_No_EEG']*100):+.2f}%)\")\n",
    "    print(f\"  EEG weight in fusion: {row['EEG_Weight']:.3f} ({row['EEG_Weight']*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "max_improvement_group = comparison_df.loc[comparison_df['EEG_Improvement'].idxmax(), 'Group']\n",
    "max_improvement_val = comparison_df.loc[comparison_df['EEG_Improvement'].idxmax(), 'EEG_Improvement']\n",
    "max_weight_group = comparison_df.loc[comparison_df['EEG_Weight'].idxmax(), 'Group']\n",
    "max_weight_val = comparison_df.loc[comparison_df['EEG_Weight'].idxmax(), 'EEG_Weight']\n",
    "\n",
    "print(f\"1. EEG provides largest improvement in {max_improvement_group} ambiguity ({max_improvement_val:+.3f})\")\n",
    "print(f\"2. EEG has highest weight in {max_weight_group} ambiguity ({max_weight_val:.3f})\")\n",
    "print(f\"3. EEG contribution varies across ambiguity levels\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}