{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Late Fusion Model with EEG Modality\n",
    "\n",
    "This notebook extends the existing late fusion model to include EEG data.\n",
    "\n",
    "**Modalities:**\n",
    "1. **Physiological data** (pupil metrics)\n",
    "2. **Behavioral data** (reaction time, decision time, etc.)\n",
    "3. **Gaze data** (gaze position, movements, fixations)\n",
    "4. **EEG data** (band powers across frequency bands and regions) \u2190 NEW\n",
    "\n",
    "**Goals:**\n",
    "1. Train separate models for each modality\n",
    "2. Compare late fusion with/without EEG\n",
    "3. Analyze EEG contribution to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Pre-Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Loaded 12511 trials from 97 subjects\n",
      "  Features extracted on: 2025-12-12 16:04:34\n",
      "  Baseline method: t3_stable_pre_decision\n",
      "\n",
      "Feature counts:\n",
      "  Physiology (POST): 13 features\n",
      "  Behavior: 7 features\n",
      "  Gaze: 20 features\n"
     ]
    }
   ],
   "source": [
    "# Load existing features (physio, behavior, gaze)",
    "with open('../data/results/features_POST/extracted_features_POST.pkl', 'rb') as f:",
    "    feature_data = pickle.load(f)",
    "",
    "merged_df = feature_data['merged_df']",
    "physio_cols = feature_data['physio_cols']",
    "behavior_cols = feature_data['behavior_cols']",
    "gaze_cols = feature_data['gaze_cols']",
    "",
    "print(f\"\u2713 Loaded {len(merged_df)} trials from {merged_df['subject_id'].nunique()} subjects\")",
    "print(f\"  Features extracted on: {feature_data['metadata']['extraction_date']}\")",
    "print(f\"  Baseline method: {feature_data['metadata']['baseline_method']}\")",
    "print(f\"\\nFeature counts:\")",
    "print(f\"  Physiology (POST): {len(physio_cols)} features\")",
    "print(f\"  Behavior: {len(behavior_cols)} features\")",
    "print(f\"  Gaze: {len(gaze_cols)} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Loaded EEG features: 10 trials\n",
      "  EEG features: 20 features\n",
      "  Frequency bands: ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
      "  Brain regions: ['Frontal', 'Central', 'Parietal', 'Occipital']\n"
     ]
    }
   ],
   "source": [
    "# Load EEG features",
    "with open('../data/results/features_POST/eeg_features_POST.pkl', 'rb') as f:",
    "    eeg_data = pickle.load(f)",
    "",
    "eeg_features_df = eeg_data['eeg_features_df']",
    "eeg_cols = eeg_data['feature_columns']",
    "",
    "print(f\"\u2713 Loaded EEG features: {len(eeg_features_df)} trials\")",
    "print(f\"  EEG features: {len(eeg_cols)} features\")",
    "print(f\"  Frequency bands: {list(eeg_data['metadata']['frequency_bands'].keys())}\")",
    "print(f\"  Brain regions: {eeg_data['metadata']['regions']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Merge EEG Features with Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2713 Merged data:\n",
      "  Total trials after merge: 10\n",
      "  Subjects: 1\n",
      "  Total features: 13 + 7 + 20 + 20 = 60\n",
      "\n",
      "\u26a0 Warning: Lost 12501 trials in merge\n",
      "  This is expected if EEG data is only available for a subset of trials\n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "1    9\n",
      "0    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge EEG features with existing features\n",
    "# Match on subject_id and trial_id\n",
    "merged_with_eeg = merged_df.merge(\n",
    "    eeg_features_df,\n",
    "    on=['subject_id', 'trial_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Merged data:\")\n",
    "print(f\"  Total trials after merge: {len(merged_with_eeg)}\")\n",
    "print(f\"  Subjects: {merged_with_eeg['subject_id'].nunique()}\")\n",
    "print(f\"  Total features: {len(physio_cols)} + {len(behavior_cols)} + {len(gaze_cols)} + {len(eeg_cols)} = {len(physio_cols) + len(behavior_cols) + len(gaze_cols) + len(eeg_cols)}\")\n",
    "\n",
    "# Check for trials lost in merge\n",
    "if len(merged_with_eeg) < len(merged_df):\n",
    "    print(f\"\\n\u26a0 Warning: Lost {len(merged_df) - len(merged_with_eeg)} trials in merge\")\n",
    "    print(f\"  This is expected if EEG data is only available for a subset of trials\")\n",
    "\n",
    "print(f\"\\nOutcome distribution:\")\n",
    "print(merged_with_eeg['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Prepare Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature array shapes:\n",
      "  X_physio: (10, 13)\n",
      "  X_behavior: (10, 7)\n",
      "  X_gaze: (10, 20)\n",
      "  X_eeg: (10, 20)\n",
      "  y: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature arrays for model training\n",
    "X_physio = SimpleImputer(strategy='mean').fit_transform(merged_with_eeg[physio_cols])\n",
    "X_behavior = SimpleImputer(strategy='mean').fit_transform(merged_with_eeg[behavior_cols])\n",
    "X_gaze = SimpleImputer(strategy='mean').fit_transform(merged_with_eeg[gaze_cols])\n",
    "X_eeg = SimpleImputer(strategy='mean').fit_transform(merged_with_eeg[eeg_cols])\n",
    "y = merged_with_eeg['outcome'].values\n",
    "subjects = merged_with_eeg['subject_id'].values\n",
    "\n",
    "print(f\"Feature array shapes:\")\n",
    "print(f\"  X_physio: {X_physio.shape}\")\n",
    "print(f\"  X_behavior: {X_behavior.shape}\")\n",
    "print(f\"  X_gaze: {X_gaze.shape}\")\n",
    "print(f\"  X_eeg: {X_eeg.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Train Individual Modality Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Physiology Model\n",
      "==================================================\n",
      "Number of subjects: 1\n",
      "\u26a0 Warning: Only 1 subject(s) available. Using train/test split instead of LOSO.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     70\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: model,\n\u001b[32m     71\u001b[39m         \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: np.mean(subject_acc_values),\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         \u001b[33m'\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m'\u001b[39m: y_true_all\n\u001b[32m     77\u001b[39m     }\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Train all modalities\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m results_physio = \u001b[43mtrain_evaluate_modality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_physio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPhysiology\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m results_behavior = train_evaluate_modality(X_behavior, y, subjects, \u001b[33m\"\u001b[39m\u001b[33mBehavior\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m results_gaze = train_evaluate_modality(X_gaze, y, subjects, \u001b[33m\"\u001b[39m\u001b[33mGaze\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_evaluate_modality\u001b[39m\u001b[34m(X, y, subjects, modality_name)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Use simple train/test split\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m model = RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, max_depth=\u001b[32m5\u001b[39m, min_samples_split=\u001b[32m10\u001b[39m,\n\u001b[32m     19\u001b[39m                                min_samples_leaf=\u001b[32m5\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     20\u001b[39m model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2940\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2936\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2938\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2940\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2942\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2945\u001b[39m     chain.from_iterable(\n\u001b[32m   2946\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2947\u001b[39m     )\n\u001b[32m   2948\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:1927\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1898\u001b[39m \n\u001b[32m   1899\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1926\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/columbia/liinc/liinc_venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2342\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2340\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2347\u001b[39m     )\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2353\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "def train_evaluate_modality(X, y, subjects, modality_name):\n",
    "    \"\"\"Train and evaluate model with LOSO cross-validation.\"\"\"\n",
    "    print(f\"\\n{'='*50}\\n{modality_name} Model\\n{'='*50}\")\n",
    "    \n",
    "    n_subjects = len(np.unique(subjects))\n",
    "    print(f\"Number of subjects: {n_subjects}\")\n",
    "    \n",
    "    # Check if we have enough subjects for LOSO\n",
    "    if n_subjects < 2:\n",
    "        print(f\"\u26a0 Warning: Only {n_subjects} subject(s) available. Using train/test split instead of LOSO.\")\n",
    "        \n",
    "        # Use simple train/test split\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "        )\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=10,\n",
    "                                       min_samples_leaf=5, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.3f}\")\n",
    "        print(f\"F1-Score: {f1:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'accuracy': acc,\n",
    "            'accuracy_sem': 0.0,  # No SEM for single split\n",
    "            'f1_score': f1,\n",
    "            'f1_sem': 0.0,\n",
    "            'predictions': y_pred,\n",
    "            'y_true': y_test\n",
    "        }\n",
    "    \n",
    "    # Standard LOSO cross-validation\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=10,\n",
    "                                   min_samples_leaf=5, random_state=42)\n",
    "    logo = LeaveOneGroupOut()\n",
    "    \n",
    "    subject_accs = {}\n",
    "    subject_f1s = {}\n",
    "    preds_all, y_true_all = [], []\n",
    "    \n",
    "    for train_idx, test_idx in logo.split(X, y, subjects):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        test_subject = subjects[test_idx][0]\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        subject_accs[test_subject] = acc\n",
    "        subject_f1s[test_subject] = f1\n",
    "        preds_all.extend(y_pred)\n",
    "        y_true_all.extend(y_test)\n",
    "    \n",
    "    subject_acc_values = np.array(list(subject_accs.values()))\n",
    "    subject_f1_values = np.array(list(subject_f1s.values()))\n",
    "    \n",
    "    print(f\"Accuracy: {np.mean(subject_acc_values):.3f} \u00b1 {stats.sem(subject_acc_values):.3f} (SEM)\")\n",
    "    print(f\"F1-Score: {np.mean(subject_f1_values):.3f} \u00b1 {stats.sem(subject_f1_values):.3f} (SEM)\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': np.mean(subject_acc_values),\n",
    "        'accuracy_sem': stats.sem(subject_acc_values),\n",
    "        'f1_score': np.mean(subject_f1_values),\n",
    "        'f1_sem': stats.sem(subject_f1_values),\n",
    "        'predictions': preds_all,\n",
    "        'y_true': y_true_all\n",
    "    }\n",
    "\n",
    "# Train all modalities\n",
    "results_physio = train_evaluate_modality(X_physio, y, subjects, \"Physiology\")\n",
    "results_behavior = train_evaluate_modality(X_behavior, y, subjects, \"Behavior\")\n",
    "results_gaze = train_evaluate_modality(X_gaze, y, subjects, \"Gaze\")\n",
    "results_eeg = train_evaluate_modality(X_eeg, y, subjects, \"EEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Late Fusion Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_fusion(X_modalities, y, subjects, modality_names, fusion_method='weighted'):\n",
    "    \"\"\"\n",
    "    Late fusion by combining modality predictions.\n",
    "    \n",
    "    fusion_method:\n",
    "    - 'average': Simple average of probabilities\n",
    "    - 'weighted': Learn weights via logistic regression (meta-learner)\n",
    "    - 'stacking': Random Forest meta-learner on probability predictions\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\\nLate Fusion: {fusion_method.upper()}\\n{'='*50}\")\n",
    "    \n",
    "    n_subjects = len(np.unique(subjects))\n",
    "    print(f\"Number of subjects: {n_subjects}\")\n",
    "    \n",
    "    # Check if we have enough subjects for LOSO\n",
    "    if n_subjects < 2:\n",
    "        print(f\"\u26a0 Warning: Only {n_subjects} subject(s) available. Using train/test split instead of LOSO.\")\n",
    "        \n",
    "        # Use simple train/test split\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # Split indices\n",
    "        indices = np.arange(len(y))\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            indices, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "        )\n",
    "        \n",
    "        # Train base models and get probabilities\n",
    "        base_models = [RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=10,\n",
    "                                              min_samples_leaf=5, random_state=42)\n",
    "                       for _ in X_modalities]\n",
    "        \n",
    "        train_probs, test_probs = [], []\n",
    "        for X, model in zip(X_modalities, base_models):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            train_probs.append(model.predict_proba(X_train)[:, 1])\n",
    "            test_probs.append(model.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        train_probs = np.column_stack(train_probs)\n",
    "        test_probs = np.column_stack(test_probs)\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Fusion\n",
    "        if fusion_method == 'average':\n",
    "            y_pred = (np.mean(test_probs, axis=1) > 0.5).astype(int)\n",
    "            weights = np.ones(len(X_modalities)) / len(X_modalities)\n",
    "        elif fusion_method == 'weighted':\n",
    "            meta = LogisticRegression(random_state=42, max_iter=1000)\n",
    "            meta.fit(train_probs, y_train)\n",
    "            weights = meta.coef_[0]\n",
    "            y_pred = meta.predict(test_probs)\n",
    "        elif fusion_method == 'stacking':\n",
    "            meta = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "            meta.fit(train_probs, y_train)\n",
    "            weights = meta.feature_importances_\n",
    "            y_pred = meta.predict(test_probs)\n",
    "        \n",
    "        # Normalize weights\n",
    "        if fusion_method == 'weighted':\n",
    "            norm_weights = np.exp(weights) / np.sum(np.exp(weights))\n",
    "        else:\n",
    "            norm_weights = weights / np.sum(weights)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.3f}\")\n",
    "        print(f\"F1-Score: {f1:.3f}\")\n",
    "        print(f\"\\nModality Weights:\")\n",
    "        for name, w in zip(modality_names, norm_weights):\n",
    "            print(f\"  {name}: {w:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'accuracy_sem': 0.0,\n",
    "            'f1_score': f1,\n",
    "            'f1_sem': 0.0,\n",
    "            'weights': norm_weights,\n",
    "            'modality_names': modality_names,\n",
    "            'predictions': y_pred,\n",
    "            'y_true': y_test\n",
    "        }\n",
    "    \n",
    "    # Standard LOSO cross-validation\n",
    "    logo = LeaveOneGroupOut()\n",
    "    base_models = [RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=10,\n",
    "                                          min_samples_leaf=5, random_state=42)\n",
    "                   for _ in X_modalities]\n",
    "    \n",
    "    subject_accs = {}\n",
    "    subject_f1s = {}\n",
    "    all_weights = []\n",
    "    preds_all, y_true_all = [], []\n",
    "    \n",
    "    for train_idx, test_idx in logo.split(X_modalities[0], y, subjects):\n",
    "        # Train base models and get probabilities\n",
    "        train_probs, test_probs = [], []\n",
    "        \n",
    "        for X, model in zip(X_modalities, base_models):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            train_probs.append(model.predict_proba(X_train)[:, 1])\n",
    "            test_probs.append(model.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        train_probs = np.column_stack(train_probs)\n",
    "        test_probs = np.column_stack(test_probs)\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Fusion\n",
    "        if fusion_method == 'average':\n",
    "            y_pred = (np.mean(test_probs, axis=1) > 0.5).astype(int)\n",
    "            weights = np.ones(len(X_modalities)) / len(X_modalities)\n",
    "            \n",
    "        elif fusion_method == 'weighted':\n",
    "            meta = LogisticRegression(random_state=42, max_iter=1000)\n",
    "            meta.fit(train_probs, y_train)\n",
    "            weights = meta.coef_[0]\n",
    "            y_pred = meta.predict(test_probs)\n",
    "            \n",
    "        elif fusion_method == 'stacking':\n",
    "            meta = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "            meta.fit(train_probs, y_train)\n",
    "            weights = meta.feature_importances_\n",
    "            y_pred = meta.predict(test_probs)\n",
    "        \n",
    "        # Store subject-level metrics\n",
    "        test_subject = subjects[test_idx][0]\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        subject_accs[test_subject] = acc\n",
    "        subject_f1s[test_subject] = f1\n",
    "        all_weights.append(weights)\n",
    "        preds_all.extend(y_pred)\n",
    "        y_true_all.extend(y_test)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    subject_acc_values = np.array(list(subject_accs.values()))\n",
    "    subject_f1_values = np.array(list(subject_f1s.values()))\n",
    "    \n",
    "    avg_weights = np.mean(all_weights, axis=0)\n",
    "    \n",
    "    # Normalize weights\n",
    "    if fusion_method == 'weighted':\n",
    "        norm_weights = np.exp(avg_weights) / np.sum(np.exp(avg_weights))\n",
    "    else:\n",
    "        norm_weights = avg_weights / np.sum(avg_weights)\n",
    "    \n",
    "    print(f\"Accuracy: {np.mean(subject_acc_values):.3f} \u00b1 {stats.sem(subject_acc_values):.3f} (SEM)\")\n",
    "    print(f\"F1-Score: {np.mean(subject_f1_values):.3f} \u00b1 {stats.sem(subject_f1_values):.3f} (SEM)\")\n",
    "    print(f\"\\nModality Weights:\")\n",
    "    for name, w in zip(modality_names, norm_weights):\n",
    "        print(f\"  {name}: {w:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': np.mean(subject_acc_values),\n",
    "        'accuracy_sem': stats.sem(subject_acc_values),\n",
    "        'f1_score': np.mean(subject_f1_values),\n",
    "        'f1_sem': stats.sem(subject_f1_values),\n",
    "        'weights': norm_weights,\n",
    "        'modality_names': modality_names,\n",
    "        'predictions': preds_all,\n",
    "        'y_true': y_true_all\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Compare Fusion With and Without EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion WITHOUT EEG (baseline)\n",
    "X_modalities_no_eeg = [X_physio, X_behavior, X_gaze]\n",
    "modality_names_no_eeg = ['Physiology', 'Behavior', 'Gaze']\n",
    "\n",
    "results_fusion_no_eeg = late_fusion(X_modalities_no_eeg, y, subjects, \n",
    "                                     modality_names_no_eeg, 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion WITH EEG\n",
    "X_modalities_with_eeg = [X_physio, X_behavior, X_gaze, X_eeg]\n",
    "modality_names_with_eeg = ['Physiology', 'Behavior', 'Gaze', 'EEG']\n",
    "\n",
    "results_fusion_with_eeg = late_fusion(X_modalities_with_eeg, y, subjects,\n",
    "                                       modality_names_with_eeg, 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'Physiology Only',\n",
    "        'Accuracy': results_physio['accuracy'],\n",
    "        'Accuracy_SEM': results_physio['accuracy_sem'],\n",
    "        'F1-Score': results_physio['f1_score'],\n",
    "        'F1_SEM': results_physio['f1_sem']\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Behavior Only',\n",
    "        'Accuracy': results_behavior['accuracy'],\n",
    "        'Accuracy_SEM': results_behavior['accuracy_sem'],\n",
    "        'F1-Score': results_behavior['f1_score'],\n",
    "        'F1_SEM': results_behavior['f1_sem']\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Gaze Only',\n",
    "        'Accuracy': results_gaze['accuracy'],\n",
    "        'Accuracy_SEM': results_gaze['accuracy_sem'],\n",
    "        'F1-Score': results_gaze['f1_score'],\n",
    "        'F1_SEM': results_gaze['f1_sem']\n",
    "    },\n",
    "    {\n",
    "        'Method': 'EEG Only',\n",
    "        'Accuracy': results_eeg['accuracy'],\n",
    "        'Accuracy_SEM': results_eeg['accuracy_sem'],\n",
    "        'F1-Score': results_eeg['f1_score'],\n",
    "        'F1_SEM': results_eeg['f1_sem']\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Fusion (No EEG)',\n",
    "        'Accuracy': results_fusion_no_eeg['accuracy'],\n",
    "        'Accuracy_SEM': results_fusion_no_eeg['accuracy_sem'],\n",
    "        'F1-Score': results_fusion_no_eeg['f1_score'],\n",
    "        'F1_SEM': results_fusion_no_eeg['f1_sem']\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Fusion (With EEG)',\n",
    "        'Accuracy': results_fusion_with_eeg['accuracy'],\n",
    "        'Accuracy_SEM': results_fusion_with_eeg['accuracy_sem'],\n",
    "        'F1-Score': results_fusion_with_eeg['f1_score'],\n",
    "        'F1_SEM': results_fusion_with_eeg['f1_sem']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Calculate EEG contribution\n",
    "acc_improvement = results_fusion_with_eeg['accuracy'] - results_fusion_no_eeg['accuracy']\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EEG Contribution: {acc_improvement:.3f} accuracy improvement\")\n",
    "print(f\"Relative improvement: {(acc_improvement / results_fusion_no_eeg['accuracy']) * 100:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[0]\n",
    "x = range(len(comparison_df))\n",
    "ax.barh(x, comparison_df['Accuracy'], xerr=comparison_df['Accuracy_SEM'], \n",
    "        capsize=5, color='steelblue', alpha=0.7)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(comparison_df['Method'])\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison (error bars = SEM)')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "# F1-Score\n",
    "ax = axes[1]\n",
    "ax.barh(x, comparison_df['F1-Score'], xerr=comparison_df['F1_SEM'],\n",
    "        capsize=5, color='coral', alpha=0.7)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(comparison_df['Method'])\n",
    "ax.set_xlabel('F1-Score')\n",
    "ax.set_title('F1-Score Comparison (error bars = SEM)')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.axvline(0.5, color='red', linestyle='--', alpha=0.3)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 8. Modality Weights Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare weights\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Without EEG\n",
    "ax = axes[0]\n",
    "weights_no_eeg = results_fusion_no_eeg['weights']\n",
    "names_no_eeg = results_fusion_no_eeg['modality_names']\n",
    "bars = ax.bar(names_no_eeg, weights_no_eeg, color='steelblue', alpha=0.7)\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Modality Weights (Without EEG)')\n",
    "ax.set_ylim([0, max(weights_no_eeg) * 1.2])\n",
    "for i, v in enumerate(weights_no_eeg):\n",
    "    ax.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# With EEG\n",
    "ax = axes[1]\n",
    "weights_with_eeg = results_fusion_with_eeg['weights']\n",
    "names_with_eeg = results_fusion_with_eeg['modality_names']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen', 'orange']\n",
    "bars = ax.bar(names_with_eeg, weights_with_eeg, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Modality Weights (With EEG)')\n",
    "ax.set_ylim([0, max(weights_with_eeg) * 1.2])\n",
    "for i, v in enumerate(weights_with_eeg):\n",
    "    ax.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. INDIVIDUAL MODALITIES:\")\n",
    "print(f\"   Physiology:  Acc={results_physio['accuracy']:.3f} \u00b1 {results_physio['accuracy_sem']:.3f}\")\n",
    "print(f\"   Behavior:    Acc={results_behavior['accuracy']:.3f} \u00b1 {results_behavior['accuracy_sem']:.3f}\")\n",
    "print(f\"   Gaze:        Acc={results_gaze['accuracy']:.3f} \u00b1 {results_gaze['accuracy_sem']:.3f}\")\n",
    "print(f\"   EEG:         Acc={results_eeg['accuracy']:.3f} \u00b1 {results_eeg['accuracy_sem']:.3f}\")\n",
    "\n",
    "print(\"\\n2. LATE FUSION:\")\n",
    "print(f\"   Without EEG: Acc={results_fusion_no_eeg['accuracy']:.3f} \u00b1 {results_fusion_no_eeg['accuracy_sem']:.3f}\")\n",
    "print(f\"   With EEG:    Acc={results_fusion_with_eeg['accuracy']:.3f} \u00b1 {results_fusion_with_eeg['accuracy_sem']:.3f}\")\n",
    "print(f\"   Improvement: {acc_improvement:+.3f} ({(acc_improvement / results_fusion_no_eeg['accuracy']) * 100:+.2f}%)\")\n",
    "\n",
    "print(\"\\n3. EEG CONTRIBUTION:\")\n",
    "eeg_weight = results_fusion_with_eeg['weights'][-1]\n",
    "print(f\"   EEG weight in fusion: {eeg_weight:.3f} ({eeg_weight*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n4. BEST METHOD:\")\n",
    "best = comparison_df.loc[comparison_df['Accuracy'].idxmax()]\n",
    "print(f\"   {best['Method']}: Acc={best['Accuracy']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liinc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}